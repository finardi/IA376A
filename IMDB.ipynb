{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Paulo Finardi  [Sem-4].ipynb",
      "provenance": [],
      "collapsed_sections": [
        "hpHsn58xAL5J",
        "c_fuTyCxP9Om",
        "ThzSeNEKIm6J",
        "xYLMb5yqud7l",
        "OAYPeXkOQnyR",
        "Wfls1IXpRZVx",
        "s-LjltlrW7A8",
        "pG0fxVNr_AQR",
        "bYEkdNJQbcOc"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/finardi/IA376A/blob/master/IMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpHsn58xAL5J",
        "colab_type": "text"
      },
      "source": [
        "# Nome: Paulo Finardi\n",
        "\n",
        "- **IMDB Week4**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_fuTyCxP9Om",
        "colab_type": "text"
      },
      "source": [
        "## Bibliotecas e Fç para fazer testes pseudo determínisticos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYYJrZbaQDfd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "64f4d4f6-614c-4274-c0ab-5c3ac8c9c881"
      },
      "source": [
        "!pip install -q  nltk\n",
        "\n",
        "import re\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "manualSeed = 0\n",
        "\n",
        "def deterministic(rep=True):\n",
        "  if rep:\n",
        "    np.random.seed(manualSeed)\n",
        "    torch.manual_seed(manualSeed)\n",
        "    if torch.cuda.is_available():\n",
        "      torch.cuda.manual_seed(manualSeed)\n",
        "      torch.cuda.manual_seed_all(manualSeed)\n",
        "    torch.backends.cudnn.enabled = False \n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    print(f'Deterministic experiment, seed: {manualSeed}')\n",
        "  else:\n",
        "    print('Random experiment')\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Using device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThzSeNEKIm6J",
        "colab_type": "text"
      },
      "source": [
        "# Download IMDB dataset \n",
        "- fast.ai\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIVVCS2GoMtf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f6ff1939-f4fe-4627-9009-3b4235b2245e"
      },
      "source": [
        "!wget -nc http://files.fast.ai/data/examples/imdb_sample.tgz\n",
        "!tar -xzf imdb_sample.tgz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-29 13:36:07--  http://files.fast.ai/data/examples/imdb_sample.tgz\n",
            "Resolving files.fast.ai (files.fast.ai)... 67.205.15.147\n",
            "Connecting to files.fast.ai (files.fast.ai)|67.205.15.147|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 571827 (558K) [application/x-gtar-compressed]\n",
            "Saving to: ‘imdb_sample.tgz’\n",
            "\n",
            "imdb_sample.tgz     100%[===================>] 558.42K  1.70MB/s    in 0.3s    \n",
            "\n",
            "2020-03-29 13:36:08 (1.70 MB/s) - ‘imdb_sample.tgz’ saved [571827/571827]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFf1MI9XRNdN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "d9161a3c-ba5d-4792-9da8-d85a3500995a"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('imdb_sample/texts.csv')\n",
        "print(df.shape)\n",
        "df['label'] = df['label'].copy()\n",
        "\n",
        "# Coluna lábel para numérica\n",
        "df['label'] = df['label'].map({'negative': int(0), 'positive': int(1)})\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>is_valid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Un-bleeping-believable! Meg Ryan doesn't even ...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>This is a extremely well-made film. The acting...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>Every once in a long while a movie will come a...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Name just says it all. I watched this movie wi...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>This movie succeeds at being one of the most u...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                               text  is_valid\n",
              "0      0  Un-bleeping-believable! Meg Ryan doesn't even ...     False\n",
              "1      1  This is a extremely well-made film. The acting...     False\n",
              "2      0  Every once in a long while a movie will come a...     False\n",
              "3      1  Name just says it all. I watched this movie wi...     False\n",
              "4      0  This movie succeeds at being one of the most u...     False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgFmqT0LkbJo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "ce7aa2bc-5de8-4ccc-a562-475ac5f2be06"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\"\"\" Exploration of number of samples classes \"\"\"\n",
        "\n",
        "# plot\n",
        "ax = sns.barplot(df.label.unique(), df.label.value_counts(), \n",
        "                 linewidth=2.5, facecolor=(0, 1, 0), edgecolor=\".1\")\n",
        "\n",
        "# decoração\n",
        "sns.despine(offset=1, trim=False)\n",
        "sns.set_style(\"ticks\")\n",
        "ax.set_ylabel('Number of samples', fontsize=16)\n",
        "plt.xticks(fontsize=16)\n",
        "plt.yticks(fontsize=16)\n",
        "plt.rcParams['figure.figsize'] = (10,3)\n",
        "\n",
        "print(f'There are {df.label.value_counts().tolist()[0]} samples of Negative class.\\\n",
        "       \\nThere are {df.label.value_counts().tolist()[1]} samples of Positive class.\\\n",
        "     ')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 524 samples of Negative class.       \n",
            "There are 476 samples of Positive class.     \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAD+CAYAAAAZKCMVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYLMb5yqud7l",
        "colab_type": "text"
      },
      "source": [
        "# Classes / fçs comuns as implementações do BoW TF-IDF e Embedding pré treinados\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTmeLmpWud45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Classe que cria o dataset\n",
        "class ImdbDataset(Dataset):\n",
        "  def __init__(self, csv_path):\n",
        "    super(ImdbDataset, self).__init__()\n",
        "    data = pd.read_csv(csv_path, index_col=0)\n",
        "    \n",
        "    self.target =  data.label.to_numpy().copy()\n",
        "    self.x      =  data.drop(['label'], axis=1).to_numpy().copy()\n",
        "\n",
        "    self.target = torch.from_numpy(self.target).type(torch.LongTensor)\n",
        "    self.x      = torch.from_numpy(self.x).type(torch.FloatTensor)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.x.shape[0]\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    return self.x[index], self.target[index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyHLCZp7V2mn",
        "colab_type": "text"
      },
      "source": [
        "## Label Smoothing and Optim\n",
        "- details in this [paper:](https://arxiv.org/pdf/1906.02629.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoYRb3o4V1_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "# Método de regularização\n",
        "class LabelSmoothing(nn.Module):\n",
        "  def __init__(self, smoothing = 0.1):\n",
        "    assert 0.0 <= smoothing < 1.0, f\"got smoothing={smoothing}\"\n",
        "    super(LabelSmoothing, self).__init__()\n",
        "    self.smoothing = smoothing\n",
        "\n",
        "  def forward(self, input, target):\n",
        "    target = target.detach()\n",
        "    log = F.log_softmax(input, dim=1)\n",
        "    oh = torch.ones_like(input).detach_()*(self.smoothing/input.size(1))\n",
        "    oh = oh.scatter_(1, target.unsqueeze(1),\n",
        "                      (1.0 - self.smoothing + self.smoothing/input.size(1)))\n",
        "    return ((-oh*log).sum(dim=1).mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R35rTnj55PP2"
      },
      "source": [
        "## Train and Eval functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FqJmRP0i5PQM",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def train(model, device, train_loader, loss_fn, optimizer):\n",
        "  model.train()\n",
        "  loss_train = []\n",
        "  for data, target in train_loader:\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = loss_fn(output, target)\n",
        "    loss_train.append(loss.item())\n",
        "  \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  \n",
        "  ave_train_loss = sum(loss_train) / len(loss_train)\n",
        "  return ave_train_loss, np.exp(ave_train_loss)\n",
        "\n",
        "def test(model, device, valid_loader, loss_fn):\n",
        "  model.eval()\n",
        "  logits, trues, loss_test = [],[],[]\n",
        "  with torch.no_grad():\n",
        "    for data, target in valid_loader:\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      output = model(data)\n",
        "      loss = loss_fn(output, target)\n",
        "      loss_test.append(loss.item())\n",
        "      \n",
        "      logits.extend(output.to('cpu').numpy().tolist())\n",
        "      trues.extend(target.to('cpu').numpy().tolist())\n",
        "      prob = F.softmax(torch.tensor(logits), dim=1).numpy().copy()\n",
        "      probs = prob[:,1]\n",
        "  \n",
        "    ave_test_loss = sum(loss_test) / len(loss_test)\n",
        "  return ave_test_loss, np.exp(ave_test_loss), accuracy_score(trues, probs.round()) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OAYPeXkOQnyR"
      },
      "source": [
        "# Processamento do texto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ebiSanRCQnyU",
        "colab": {}
      },
      "source": [
        "REP_SEM_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])\")\n",
        "REP_COM_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QQJJNcRvQnyX",
        "colab": {}
      },
      "source": [
        "def preprocess_reviews(reviews):\n",
        "    reviews = [REP_SEM_SPACE.sub(\"\", r.lower()) for r in reviews]\n",
        "    reviews = [REP_COM_SPACE.sub(\" \", r) for r in reviews]\n",
        "    return reviews"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vzimr1cZQnyZ",
        "colab": {}
      },
      "source": [
        "reviews_clean = preprocess_reviews(df.text.to_list())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2vr4773MQnya",
        "colab": {}
      },
      "source": [
        "reviews_tokenized = [nltk.word_tokenize(review) for review in reviews_clean] # tokenização"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DFn9FHmLQnyc"
      },
      "source": [
        "## Palavras mais frequentes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Skx0VckyQnye",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "\n",
        "# Extrair as palavras das reviews positivas\n",
        "pos_words = [reviews_tokenized[i] for i in range(len(reviews_tokenized)) if df.label.to_list()[i] == 1]\n",
        "pos_words = list(itertools.chain.from_iterable(pos_words))\n",
        "\n",
        "# Extrair as palavras das reviews negativas\n",
        "neg_words = [reviews_tokenized[i] for i in range(len(reviews_tokenized)) if df.label.to_list()[i] == 0]\n",
        "neg_words = list(itertools.chain.from_iterable(neg_words))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JKHB8OwGQnyg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bfd32626-ccda-458e-9b8e-fb749a735074"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "\n",
        "# Remover stop words\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "stop_words.add('movie')\n",
        "stop_words.add('film')\n",
        "stop_words.add('character')\n",
        "stop_words.add('characters')\n",
        "stop_words.add('br')\n",
        "pos_words_final = [word for word in pos_words if word not in stop_words]\n",
        "neg_words_final = [word for word in neg_words if word not in stop_words]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2oyPmWV-Qnyi",
        "colab": {}
      },
      "source": [
        "# Calcular a frequência das distribuições das palavras nas reviews positivas e negativas\n",
        "fd_pos = nltk.FreqDist(p for p in pos_words_final)\n",
        "fd_neg = nltk.FreqDist(n for n in neg_words_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P_6ImDKGQnyl",
        "colab": {}
      },
      "source": [
        "most_common_pos = fd_pos.most_common(30) # 30 palavras mais comuns na review positiva\n",
        "most_common_neg = fd_neg.most_common(30) # 30 palavras mais comuns na review negativa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1JJTQvWcQnyn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "outputId": "f1b8f775-e6e7-451e-dda4-992b42fda97f"
      },
      "source": [
        "plt.bar(range(len(most_common_pos)), [val[1] for val in most_common_pos])\n",
        "plt.xticks(range(len(most_common_pos)), [val[0] for val in most_common_pos])\n",
        "plt.xticks(rotation=80)\n",
        "plt.title('30 palavras mais comuns em reviews positivas')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAADtCAYAAAB9NzuAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njIyMjIyMjEwf8b9WBiQ6jRLZrwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-yyrJxHnQnyq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "outputId": "2f1d607c-0643-42d4-cdf7-3ab6e79fc99f"
      },
      "source": [
        "plt.bar(range(len(most_common_neg)), [val[1] for val in most_common_neg])\n",
        "plt.xticks(range(len(most_common_neg)), [val[0] for val in most_common_neg])\n",
        "plt.xticks(rotation=80)\n",
        "plt.title('30 palavras mais comuns em reviews negativas')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAADtCAYAAAB9NzuAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFi1atGjpIP4Pp/XaPDTwepcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "831FXGZbQnys",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d2926fbe-d615-4341-c569-17ea2b7a8d5f"
      },
      "source": [
        "# Verificando a interseção das palavras que aparecem nas reviews positivas e negativas\n",
        "inter = list(set(pos_words_final).intersection(set(neg_words_final)))\n",
        "print(f'Existem: {len(inter)} words comuns nas reviews positivas e Negativas.\\n\\\n",
        "        As 10ª são: {inter[:10]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Existem: 6774 words comuns nas reviews positivas e Negativas.\n",
            "        As 10ª são: ['wedding', 'orders', 'shadows', 'drugs', 'humble', 'stories', 'besides', 'omar', 'someplace', 'freudian']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sutWOZa8Qnyt"
      },
      "source": [
        "## Removendo stop words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "chh1v1-QQnyx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1149467c-896e-4c83-f17c-661c20c0e7d2"
      },
      "source": [
        "\"\"\" Removendo stop words \"\"\"\n",
        "tokenized_processed = []\n",
        "for i in range(len(reviews_tokenized)):\n",
        "  review = []\n",
        "  for j in reviews_tokenized[i]:\n",
        "    if j not in stop_words: \n",
        "      review.append(j)\n",
        "  tokenized_processed.append(review)\n",
        "\n",
        "print(f'Texto tokenizado e limpo: {tokenized_processed[:1]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto tokenizado e limpo: [['un', 'bleeping', 'believable', 'meg', 'ryan', 'doesnt', 'even', 'look', 'usual', 'pert', 'lovable', 'self', 'normally', 'makes', 'forgive', 'shallow', 'ticky', 'acting', 'schtick', 'hard', 'believe', 'producer', 'dog', 'plus', 'kevin', 'kline', 'kind', 'suicide', 'trip', 'career', 'whoosh', 'banzai', 'finally', 'directed', 'guy', 'big', 'chill', 'must', 'replay', 'jonestown', 'hollywood', 'style', 'wooofff']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MlvHxt0TQnyy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0a9348a1-15fa-4ad6-ceb6-50caba8a080b"
      },
      "source": [
        "reviews = [' '.join(t) for t in tokenized_processed] # juntando as reviews ()\n",
        "reviews[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'every long come along awful feel compelled warn people labor days save one soul watching great joy begin discussion pain starters musical montage every five minutes development every stereotype swearing guy fat guy eats donuts goofy foreign guy etc script felt written shot production value incredibly low felt like watching junior high video presentation directors producers etc ever even seen halestorm getting worse worse every new entry concept sounded funny could go wrong gary coleman handful somewhat legitimate actors trust say things went wrong wrong'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xEBG11vQny0",
        "colab": {}
      },
      "source": [
        "labels = df.label.to_list() # labels "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wfls1IXpRZVx",
        "colab_type": "text"
      },
      "source": [
        "# MLP com TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTCCHVRBReas",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.utils.data import TensorDataset\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k9aTkxoRvHX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Essa função é o Tfid que faz o BoW\n",
        "def encoder_BoW(X_train,X_test):\n",
        "  tfid = TfidfVectorizer()\n",
        "  tfid.fit(X_train)\n",
        "  return tfid.transform(X_train), tfid.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoJZK7NGR753",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X, test_X, train_y, test_y = train_test_split(reviews, \n",
        "                                                    labels, \n",
        "                                                    shuffle=True, \n",
        "                                                    test_size=0.2, \n",
        "                                                    random_state=123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpGmvkw0SEjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test = encoder_BoW(train_X, test_X) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdLlKM4QSEVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cria o dataset (Pandas DF) de treino\n",
        "df_train = pd.DataFrame(X_train.toarray())\n",
        "df_train['label'] = train_y\n",
        "cols = df_train.columns.tolist()\n",
        "cols = cols[-1:] + cols[:-1]\n",
        "df_train = df_train[cols]\n",
        "\n",
        "# Cria o dataset (Pandas DF) de teste\n",
        "df_test = pd.DataFrame(X_test.toarray())\n",
        "df_test['label'] = test_y\n",
        "cols = df_test.columns.tolist()\n",
        "cols = cols[-1:] + cols[:-1]\n",
        "df_test = df_test[cols]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYXPH6lRSERo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "137f4217-fe2e-450f-c2ff-28b25f2a9a20"
      },
      "source": [
        "# Eu escolhi salvar e chamar os conj. de dados para minha classe dataset \n",
        "df_train.to_csv('train.csv')\n",
        "df_test.to_csv('test.csv')\n",
        "\n",
        "df_train = pd.read_csv('train.csv',index_col=0)\n",
        "df_test  = pd.read_csv('test.csv', index_col=0)\n",
        "\n",
        "print(f'df_train.shape: {df_train.shape}') \n",
        "print(f'df_test.shape: {df_test.shape}') \n",
        "\n",
        "# teste de sanidade:\n",
        "trn = pd.read_csv('train.csv', index_col=0)\n",
        "trn.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df_train.shape: (800, 17300)\n",
            "df_test.shape: (200, 17300)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>17259</th>\n",
              "      <th>17260</th>\n",
              "      <th>17261</th>\n",
              "      <th>17262</th>\n",
              "      <th>17263</th>\n",
              "      <th>17264</th>\n",
              "      <th>17265</th>\n",
              "      <th>17266</th>\n",
              "      <th>17267</th>\n",
              "      <th>17268</th>\n",
              "      <th>17269</th>\n",
              "      <th>17270</th>\n",
              "      <th>17271</th>\n",
              "      <th>17272</th>\n",
              "      <th>17273</th>\n",
              "      <th>17274</th>\n",
              "      <th>17275</th>\n",
              "      <th>17276</th>\n",
              "      <th>17277</th>\n",
              "      <th>17278</th>\n",
              "      <th>17279</th>\n",
              "      <th>17280</th>\n",
              "      <th>17281</th>\n",
              "      <th>17282</th>\n",
              "      <th>17283</th>\n",
              "      <th>17284</th>\n",
              "      <th>17285</th>\n",
              "      <th>17286</th>\n",
              "      <th>17287</th>\n",
              "      <th>17288</th>\n",
              "      <th>17289</th>\n",
              "      <th>17290</th>\n",
              "      <th>17291</th>\n",
              "      <th>17292</th>\n",
              "      <th>17293</th>\n",
              "      <th>17294</th>\n",
              "      <th>17295</th>\n",
              "      <th>17296</th>\n",
              "      <th>17297</th>\n",
              "      <th>17298</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.124306</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038289</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06225</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 17300 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label    0    1    2    3    4  ...  17293  17294  17295  17296  17297  17298\n",
              "0      0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0\n",
              "1      0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0\n",
              "2      0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0\n",
              "3      0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0\n",
              "4      1  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0\n",
              "\n",
              "[5 rows x 17300 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BRCURh3-3LV",
        "colab_type": "text"
      },
      "source": [
        "## ImdbDataset Class\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAqGXfrFQMMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Classe que cria o dataset\n",
        "class ImdbDataset(Dataset):\n",
        "  def __init__(self, csv_path):\n",
        "    super(ImdbDataset, self).__init__()\n",
        "    data = pd.read_csv(csv_path, index_col=0)\n",
        "    \n",
        "    self.target =  data.label.to_numpy().copy()\n",
        "    self.x      =  data.drop(['label'], axis=1).to_numpy().copy()\n",
        "\n",
        "    self.target = torch.from_numpy(self.target).type(torch.LongTensor)\n",
        "    self.x      = torch.from_numpy(self.x).type(torch.FloatTensor)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.x.shape[0]\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    return self.x[index], self.target[index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqZlXss-TfwF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62815ca7-c129-4b3e-f15a-e92a9c7c8e88"
      },
      "source": [
        "# teste de sanidade:\n",
        "ds = ImdbDataset('train.csv')\n",
        "x0, y0 = ds[4]\n",
        "x0, y0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0., 0., 0.,  ..., 0., 0., 0.]), tensor(1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAk6DQ1yTfuQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "36cb6025-5000-4dc4-a716-e240e2ece622"
      },
      "source": [
        "# teste de sanidade:\n",
        "train_loader = DataLoader(ds, 100, shuffle=False)\n",
        "x, y = next(iter(train_loader))\n",
        "\n",
        "print(f'input shape: {x.shape}') \n",
        "print(f'label shape: {y.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input shape: torch.Size([100, 17299])\n",
            "label shape: torch.Size([100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-LjltlrW7A8",
        "colab_type": "text"
      },
      "source": [
        "# Modelo MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbhuNuUouDm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, vocab_dim, neur1, neur2, drop, out):\n",
        "    super(MLP, self).__init__()\n",
        "    \n",
        "    self.norm0 = nn.LayerNorm(vocab_dim) # <- norm. do dado de entrada\n",
        "    self.drop = nn.Dropout(drop)\n",
        "    self.relu = nn.ReLU() \n",
        "    \n",
        "    self.fc0 = nn.Linear(vocab_dim, neur1)\n",
        "    self.fc1 = nn.Linear(neur1, neur2)\n",
        "    self.fc2 = nn.Linear(neur2, out) \n",
        "\n",
        "  def forward(self, x):\n",
        "    o = self.norm0(x)\n",
        "    o = self.drop(self.relu(self.fc0(o)))\n",
        "    o = self.drop(self.relu(self.fc1(o)))\n",
        "    return self.fc2(o)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNsSvtlWatOQ",
        "colab_type": "text"
      },
      "source": [
        "### Glorot init para os pesos e zero init para os bias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgOSxS0FZP_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pesos iniciados com valores (0,std²)\n",
        "def weights_init(m):\n",
        "  if isinstance(m, nn.Linear):\n",
        "    torch.nn.init.xavier_normal_(m.weight.data, gain=nn.init.calculate_gain('relu'))\n",
        "    torch.nn.init.zeros_(m.bias.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5-H9f2yuDko",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "867578df-e2a6-41fe-f04d-b4c278bb41e5"
      },
      "source": [
        "# Hyperparams do modelo\n",
        "VOCAB_SIZE, H1,H2,D,O, = df_train.shape[1] -1, 70, 39, 0.5, df.label.nunique()\n",
        "\n",
        "model       = MLP(VOCAB_SIZE, H1, H2, D, O)\n",
        "# model.apply(weights_init)\n",
        "\n",
        "# teste de sanidade:\n",
        "x,y = next(iter(train_loader))\n",
        "model(x).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-8z3-ly_eu0",
        "colab_type": "text"
      },
      "source": [
        "## Dataloaders, Minibatches and Criterion\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsOA55HJgTTN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9cb1e717-8765-4aa8-9b5a-88d652bc7779"
      },
      "source": [
        "BATCH_SIZE = 20\n",
        "\n",
        "# Cria datasets (train / valid)\n",
        "dataset_train  = ImdbDataset('train.csv')\n",
        "dataset_valid  = ImdbDataset('test.csv')\n",
        "\n",
        "# Cria o dataloder_bow de treino\n",
        "train_loader_bow = DataLoader(dataset=dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# Cria o dataloader_bow de valid\n",
        "valid_loader_bow = DataLoader(dataset=dataset_valid, batch_size=BATCH_SIZE, shuffle=False)                       \n",
        "\n",
        "print(len(train_loader_bow), len(valid_loader_bow))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pG0fxVNr_AQR",
        "colab_type": "text"
      },
      "source": [
        "# Busca de hyperparams - Optuna\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1IE49M-dcwm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "783ab350-b6fa-4d4f-f172-7377995be09d"
      },
      "source": [
        "!pip install -q optuna\n",
        "!pip install -q torch_optimizer\n",
        "import torch_optimizer as optim\n",
        "import optuna\n",
        "from optuna.samplers import RandomSampler"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 153kB 33.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 47.4MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 12.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 10.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 65.3MB/s \n",
            "\u001b[?25h  Building wheel for alembic (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for optuna (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5euDxHNdcr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCH = 10\n",
        "\n",
        "# Função trial que busca o melhor optmin e a melhor lr\n",
        "def get_optimizer(trial, model):\n",
        "    optimizer_name = trial.suggest_categorical('optimizer', ['AdaMod', 'Yogi'])\n",
        "    lr_optmzd = trial.suggest_uniform('optim_lr', 3*1e-4, 2*1e-3)\n",
        "    return getattr(optim, optimizer_name)(model.parameters(), lr=lr_optmzd)\n",
        "\n",
        "# Função obj que tenta max a acurácia\n",
        "def objective(trial):\n",
        "  h1     = int(trial.suggest_uniform(\"h1_units\", 60, 90))\n",
        "  h2     = int(trial.suggest_uniform(\"h2_units\", 20, 50))\n",
        "  drop   = trial.suggest_uniform(\"drop\", 0.2, 0.7)\n",
        "  smooth = trial.suggest_uniform(\"smooth\", 0.1, 0.35)\n",
        "  \n",
        "  criterion = LabelSmoothing(smooth)     \n",
        "  model     = MLP(VOCAB_SIZE, h1, h2, drop, O).to(device)\n",
        "  model.apply(weights_init)    \n",
        "  optimizer = get_optimizer(trial, model)\n",
        "\n",
        "  for step in range(EPOCH):\n",
        "    loss_train, _ = train(model, device, train_loader_bow, criterion, optimizer)\n",
        "    loss_valid, _, acc = test(model, device, valid_loader_bow, criterion)\n",
        "\n",
        "  return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iztIgc6nMQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "deterministic() # <- ter certeza que tudo foi zerado para o teste ser reproduzível\n",
        "\n",
        "# Running optuna\n",
        "study = optuna.create_study(direction='maximize', sampler=RandomSampler(manualSeed))\n",
        "study.optimize(objective, n_trials=200)\n",
        "print('Number of finished trials: ', len(study.trials))\n",
        "print('Best trial:')\n",
        "trial = study.best_trial\n",
        "print('  Value: ', trial.value)\n",
        "print('  Params: ')\n",
        "\n",
        "for key, value in trial.params.items():\n",
        "    print(f'    {key}: {value}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0IpOsCch0xa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "1feae1fe-14d2-4da8-ad37-16ecfc5ea758"
      },
      "source": [
        "# Melhor conj. de params encontrado\n",
        "study.best_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'drop': 0.358600871034648,\n",
              " 'h1_units': 70.14022844516676,\n",
              " 'h2_units': 40.242569667770624,\n",
              " 'optim_lr': 0.0009268327901236391,\n",
              " 'optimizer': 'Yogi',\n",
              " 'smooth': 0.29458637050647724}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arKdxyc5BryW",
        "colab_type": "text"
      },
      "source": [
        "## Optuna Visualization\n",
        "- nice plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9HBN5SO-XEx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "243c8f4a-1f69-4e8d-eacb-37085d647886"
      },
      "source": [
        "optuna.visualization.plot_optimization_history(study)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"12aa4c4f-1ebb-4b13-a14c-0cf9afb72066\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"12aa4c4f-1ebb-4b13-a14c-0cf9afb72066\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '12aa4c4f-1ebb-4b13-a14c-0cf9afb72066',\n",
              "                        [{\"mode\": \"markers\", \"name\": \"Objective Value\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199], \"y\": [0.87, 0.845, 0.835, 0.84, 0.85, 0.835, 0.81, 0.83, 0.8, 0.83, 0.825, 0.875, 0.845, 0.84, 0.83, 0.845, 0.83, 0.85, 0.85, 0.845, 0.835, 0.805, 0.84, 0.83, 0.85, 0.815, 0.82, 0.835, 0.825, 0.835, 0.815, 0.85, 0.845, 0.81, 0.85, 0.845, 0.83, 0.825, 0.835, 0.805, 0.855, 0.82, 0.845, 0.865, 0.825, 0.815, 0.84, 0.825, 0.84, 0.81, 0.825, 0.835, 0.835, 0.82, 0.87, 0.83, 0.845, 0.825, 0.845, 0.805, 0.84, 0.83, 0.805, 0.84, 0.84, 0.855, 0.805, 0.82, 0.815, 0.83, 0.82, 0.855, 0.82, 0.84, 0.82, 0.815, 0.845, 0.83, 0.815, 0.825, 0.81, 0.855, 0.84, 0.835, 0.83, 0.845, 0.84, 0.83, 0.865, 0.82, 0.825, 0.82, 0.825, 0.825, 0.84, 0.795, 0.845, 0.82, 0.835, 0.84, 0.84, 0.835, 0.81, 0.845, 0.855, 0.845, 0.83, 0.825, 0.82, 0.835, 0.835, 0.815, 0.85, 0.835, 0.85, 0.845, 0.86, 0.82, 0.84, 0.8, 0.815, 0.835, 0.83, 0.805, 0.83, 0.855, 0.84, 0.83, 0.805, 0.785, 0.84, 0.83, 0.82, 0.84, 0.835, 0.83, 0.85, 0.815, 0.845, 0.835, 0.855, 0.81, 0.84, 0.81, 0.84, 0.835, 0.835, 0.84, 0.845, 0.815, 0.83, 0.85, 0.835, 0.8, 0.84, 0.83, 0.805, 0.855, 0.81, 0.84, 0.81, 0.84, 0.83, 0.84, 0.835, 0.82, 0.855, 0.825, 0.815, 0.83, 0.86, 0.83, 0.84, 0.825, 0.845, 0.855, 0.815, 0.83, 0.835, 0.805, 0.85, 0.84, 0.845, 0.81, 0.8, 0.85, 0.87, 0.785, 0.79, 0.8, 0.84, 0.835, 0.835, 0.845, 0.81, 0.835, 0.84, 0.825, 0.855, 0.86]}, {\"name\": \"Best Value\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199], \"y\": [0.87, 0.87, 0.87, 0.87, 0.87, 0.87, 0.87, 0.87, 0.87, 0.87, 0.87, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Optimization History Plot\"}, \"xaxis\": {\"title\": {\"text\": \"#Trials\"}}, \"yaxis\": {\"title\": {\"text\": \"Objective Value\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('12aa4c4f-1ebb-4b13-a14c-0cf9afb72066');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5u1KiLV7moc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "920de388-f9ec-4b37-b6f0-15e3417f22d8"
      },
      "source": [
        "optuna.visualization.plot_parallel_coordinate(study)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"3abb5360-d6ab-46bc-9217-4e0035aac4bb\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"3abb5360-d6ab-46bc-9217-4e0035aac4bb\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '3abb5360-d6ab-46bc-9217-4e0035aac4bb',\n",
              "                        [{\"dimensions\": [{\"label\": \"Objective Value\", \"range\": [0.785, 0.875], \"values\": [0.87, 0.845, 0.835, 0.84, 0.85, 0.835, 0.81, 0.83, 0.8, 0.83, 0.825, 0.875, 0.845, 0.84, 0.83, 0.845, 0.83, 0.85, 0.85, 0.845, 0.835, 0.805, 0.84, 0.83, 0.85, 0.815, 0.82, 0.835, 0.825, 0.835, 0.815, 0.85, 0.845, 0.81, 0.85, 0.845, 0.83, 0.825, 0.835, 0.805, 0.855, 0.82, 0.845, 0.865, 0.825, 0.815, 0.84, 0.825, 0.84, 0.81, 0.825, 0.835, 0.835, 0.82, 0.87, 0.83, 0.845, 0.825, 0.845, 0.805, 0.84, 0.83, 0.805, 0.84, 0.84, 0.855, 0.805, 0.82, 0.815, 0.83, 0.82, 0.855, 0.82, 0.84, 0.82, 0.815, 0.845, 0.83, 0.815, 0.825, 0.81, 0.855, 0.84, 0.835, 0.83, 0.845, 0.84, 0.83, 0.865, 0.82, 0.825, 0.82, 0.825, 0.825, 0.84, 0.795, 0.845, 0.82, 0.835, 0.84, 0.84, 0.835, 0.81, 0.845, 0.855, 0.845, 0.83, 0.825, 0.82, 0.835, 0.835, 0.815, 0.85, 0.835, 0.85, 0.845, 0.86, 0.82, 0.84, 0.8, 0.815, 0.835, 0.83, 0.805, 0.83, 0.855, 0.84, 0.83, 0.805, 0.785, 0.84, 0.83, 0.82, 0.84, 0.835, 0.83, 0.85, 0.815, 0.845, 0.835, 0.855, 0.81, 0.84, 0.81, 0.84, 0.835, 0.835, 0.84, 0.845, 0.815, 0.83, 0.85, 0.835, 0.8, 0.84, 0.83, 0.805, 0.855, 0.81, 0.84, 0.81, 0.84, 0.83, 0.84, 0.835, 0.82, 0.855, 0.825, 0.815, 0.83, 0.86, 0.83, 0.84, 0.825, 0.845, 0.855, 0.815, 0.83, 0.835, 0.805, 0.85, 0.84, 0.845, 0.81, 0.8, 0.85, 0.87, 0.785, 0.79, 0.8, 0.84, 0.835, 0.835, 0.845, 0.81, 0.835, 0.84, 0.825, 0.855, 0.86]}, {\"label\": \"drop\", \"range\": [0.20816425134185396, 0.6961981994443163], \"values\": [0.501381688035822, 0.2283564886587216, 0.6627983191463305, 0.2701753902063226, 0.2591372129344666, 0.43680020967332867, 0.5088177485379385, 0.5065317289420661, 0.30519128053692046, 0.5171370289786674, 0.32664580126989107, 0.358600871034648, 0.6189724537494019, 0.42557960726046407, 0.25936385947712204, 0.6325512806526925, 0.35928447622566184, 0.3989103763793145, 0.33500398659608244, 0.6480191937545385, 0.5497396376587521, 0.35660916597297543, 0.5219950996148186, 0.3439955021816402, 0.4849824553506324, 0.3106313425918914, 0.5519442917701831, 0.6523238721047566, 0.6036594793625053, 0.41003768489530534, 0.3799890322391819, 0.28974513045892786, 0.5522072009617663, 0.6961981994443163, 0.3559724977398009, 0.42605451751671286, 0.3558979409970513, 0.5719172726548938, 0.308448492199237, 0.6522124878446157, 0.3367710174078179, 0.5943697137660182, 0.2128313590272658, 0.29322910974466926, 0.5584298405962969, 0.262416528745043, 0.24171121772100929, 0.5386316526692134, 0.34086505287697455, 0.5032377300342878, 0.5996012936761959, 0.5866630048052849, 0.44869568274933136, 0.4005661707793138, 0.6804173290315001, 0.5876098887333054, 0.5852903742513881, 0.4160740249624083, 0.2657413996455638, 0.4210076588974351, 0.22842403821662016, 0.23492950866967305, 0.22230615062705705, 0.40728374257472655, 0.46808874735172595, 0.27993503357146265, 0.42930198088429294, 0.4900985528816297, 0.5981957372586658, 0.24873434436274494, 0.279707231724478, 0.5638481715658243, 0.20816425134185396, 0.24923900168198543, 0.21653729573775282, 0.49007585813548854, 0.6871281064090251, 0.5200120776497191, 0.531252285766338, 0.4139171894157362, 0.662483455976596, 0.39087990361814084, 0.2529530774411161, 0.2569083201949306, 0.31890362126951943, 0.5691951688468062, 0.5753824309431759, 0.5058742072164789, 0.39140402957892706, 0.3293511610357506, 0.4008567676897993, 0.21326127629948788, 0.32682126212841134, 0.46504446797961146, 0.6396173815156635, 0.4301098531956936, 0.2121565998550789, 0.2497081971807042, 0.5235983269470179, 0.42033304651706904, 0.4210178188649626, 0.469559117493386, 0.6358928673777464, 0.34355963084208374, 0.6760713486477103, 0.4904436370738985, 0.32369937776957686, 0.4173803221362171, 0.3810945294696947, 0.3465722012532825, 0.319206640462029, 0.49639013533830423, 0.39862837358402103, 0.3333484388002219, 0.2738427891033537, 0.28970503493674443, 0.6240751901734924, 0.5824972237830401, 0.4905409648360315, 0.4365950238549485, 0.25865778209159695, 0.6283776235348242, 0.23502109507232233, 0.616657903809233, 0.25489222903125036, 0.5410594793676106, 0.38254993853000485, 0.5167074107485405, 0.332519849182241, 0.6555985807383639, 0.46411704458926784, 0.37510363048200046, 0.579641225858334, 0.26595162487018964, 0.27992264342709566, 0.28504981950435637, 0.3502018415792436, 0.21645066727667578, 0.42925158353322246, 0.402153263154407, 0.3082286304721049, 0.3027831613204315, 0.6090166528779192, 0.40346096570647394, 0.6879419342092666, 0.2123765395581454, 0.554517730091645, 0.5341169864746385, 0.2915166460399606, 0.28402126068399, 0.6291688193171312, 0.6272300140465135, 0.34644428251350734, 0.4729587982339522, 0.45781917332562583, 0.2170353826524904, 0.6685585209702588, 0.49279669056758774, 0.29275894876158814, 0.33320395111049295, 0.48885471215842013, 0.6393001874592397, 0.4839230007387537, 0.3557430342461606, 0.638013423960287, 0.2822442058468861, 0.4832530534945813, 0.47988711564736836, 0.5627867670507447, 0.3698781897614599, 0.2754674486555208, 0.3213186633054541, 0.5638856366072089, 0.5504640317700626, 0.6447239544079333, 0.267409322844821, 0.5674068873152804, 0.4335597035844184, 0.6026319277895875, 0.5146883541121394, 0.3147837223459749, 0.43985357667746594, 0.5543851954705243, 0.2621444469454724, 0.21047503463386524, 0.4450551324927591, 0.624172634895003, 0.3263499672267328, 0.3271912005588121, 0.42636524821335997, 0.6266229880792564, 0.4068792144064374, 0.55757162601268, 0.4750272546381569, 0.27601361360478477, 0.2633638356212666, 0.3989593074174689, 0.6418897183347723, 0.2601386724897348, 0.5521356469655592]}, {\"label\": \"h1_units\", \"range\": [60.14086428577641, 89.93752573306628], \"values\": [76.46440511781975, 71.531451218781, 75.86684759258713, 71.04724619521645, 73.84438086758796, 82.75846872967071, 77.05301846605946, 87.07795426588214, 80.00300146337003, 69.75141687025058, 64.83928553654988, 70.14022844516676, 84.62979689543805, 75.28873130159701, 63.60589683639507, 66.50466412882629, 77.27839486668537, 85.24158357592063, 60.14086428577641, 82.68320081595122, 73.41376135852882, 80.26317243600708, 75.03973145780107, 74.10396567767296, 64.06422192667351, 89.06885295780822, 86.75770065047016, 74.07747521970727, 63.71459948548325, 89.47724879475581, 85.67410027177833, 74.6864681067328, 70.36055042090709, 61.511101702726314, 77.69729929063713, 66.56248121210315, 61.74087480971627, 76.27496325031193, 86.90013879121027, 66.87657969259739, 78.86945530773446, 73.68389316368587, 66.39935932102446, 79.38793311944055, 75.52137321462342, 66.14597286541337, 82.45990859551642, 66.27471088442523, 80.0974963977273, 77.4134141156439, 88.47956467247045, 85.33650238415828, 89.4548816945476, 72.84671496349225, 85.8657455226505, 71.9849673094827, 81.76783092631736, 80.32235488415833, 81.81132788133985, 73.75543656709952, 65.43452885210709, 80.44077387290207, 65.91162840556919, 86.48127868178713, 72.91207318524184, 69.77054299250446, 73.70734264937298, 72.78917640969716, 67.20060820139129, 88.61164141991495, 87.26531155238214, 88.10239421368365, 70.66106545415789, 80.40810453138089, 66.9823238783717, 76.33772632150523, 63.46452891416244, 84.94558199616412, 68.65195491994481, 85.61820352615915, 70.81636681457677, 88.1185309175327, 89.76033730243422, 71.55712255649783, 71.22888549962748, 86.57886807006355, 86.01868216387395, 81.23752388026304, 63.93867985419768, 89.38719755593469, 68.14958302818438, 68.33321020894532, 85.86955640507708, 75.31886720808541, 70.25094344594197, 79.05170396946448, 62.684836350987005, 89.0659229926206, 88.46583062161523, 87.44371980805806, 83.72520489682215, 73.83020488048184, 64.00384412804803, 63.62758083417402, 65.2431601248282, 77.93810191297406, 62.294603070908565, 74.24003964090339, 69.13339093042134, 89.10665411680752, 74.32939508629248, 77.76241988036276, 77.73080702611475, 88.12905676012844, 80.94745433454872, 67.81886000677859, 77.69084169040653, 83.42793398655992, 62.91773984362922, 86.89743766006863, 72.71119060366418, 61.766108499031546, 72.95280382962957, 69.7224807449258, 60.898509747142484, 60.88904454390904, 72.12730853817776, 83.12023487153132, 66.64189338878316, 71.0846908007831, 65.98788426360343, 71.64958810669448, 80.7235432846959, 67.62075693121072, 75.7313943323166, 78.26965842662304, 88.9916991431368, 88.09851324570336, 69.54700527531188, 83.24050425254407, 80.27067442932801, 74.4867486774387, 72.80713080633221, 67.41135636166314, 77.89299196048869, 80.21512029701431, 71.32219717766662, 79.62245794459444, 63.37281951636934, 80.34178230636037, 87.97181816881483, 81.81749718986345, 87.44589263500148, 84.7439311684394, 72.2917861689223, 64.69960474092316, 64.20948053770258, 63.18764729802598, 74.75676695125034, 66.12216184590987, 81.82640973994589, 80.07710891311007, 74.59231346665996, 87.97996594631704, 66.3436438734724, 79.77803599283965, 62.893525820921525, 77.22095518884956, 76.63935175860779, 67.14033832471438, 84.60067307609255, 85.90428655461128, 81.55879171023456, 89.23765968435063, 75.66527607006357, 74.74774281508547, 62.07547976377168, 71.0113873332311, 77.7319614250197, 81.00133504547806, 60.36513470829776, 63.543801050243275, 60.3019108696828, 63.47584360033148, 68.62633506841685, 83.52343050881602, 88.45620903386524, 63.86089841932559, 81.5816718601192, 61.3204908687958, 72.9034795313022, 60.41595138911352, 69.31887654873918, 80.56244798123316, 88.9654991741242, 65.56343909782862, 79.1838832342203, 89.93752573306628, 75.73731202435877, 69.53693608022881]}, {\"label\": \"h2_units\", \"range\": [20.08109641680508, 49.938867539860205], \"values\": [41.455680991172585, 28.92603819633417, 37.04133683281797, 48.71465476859139, 43.41587528859367, 23.177228215633765, 20.563694013090654, 33.498499697336825, 40.11913608854478, 21.152762794182042, 39.59324976396195, 40.242569667770624, 22.913038273791837, 21.67144081104819, 28.884205925664347, 36.95566599814626, 47.87888592728642, 27.94190492850349, 40.334496103886906, 31.882948262700868, 45.39226017413384, 27.493888269649343, 48.68250904169672, 41.4822359368593, 28.948469778680924, 29.629917241204925, 44.185819671382575, 45.23420389356798, 45.44024687966703, 31.198722523497644, 20.35142252555006, 30.16955350339335, 47.842438803967724, 40.97294224155533, 41.903660885503086, 37.08720603724214, 33.03249876674362, 45.63840740932143, 49.71016842190113, 46.447561976317424, 46.17951966342186, 34.50225849796258, 35.546021417919896, 26.446422102517346, 23.9620431903546, 24.94876604260272, 47.111592192378005, 28.607451299018138, 43.55458736069413, 43.62626467865078, 48.24133114119496, 25.8302666882895, 34.35110921119964, 28.93525455665169, 49.18758467069391, 29.054926277825498, 20.34282375875093, 44.31272273779672, 28.10983715716144, 35.737778622645436, 43.65636536919556, 25.351020479309515, 33.795676512680224, 34.652301798211695, 35.30050556954751, 24.410416846664038, 46.461242306896686, 34.196620218371315, 24.81616467455769, 36.734339026486154, 44.46571456305706, 33.421348838213994, 30.701206712076285, 38.27532744675164, 38.43394119430623, 20.973958869537913, 38.55440778538244, 44.21068507961303, 27.24255860229722, 34.930339356069524, 44.85970743667213, 27.717004564141803, 27.482601231693536, 47.50181057990545, 42.463647726203995, 30.556116827817668, 48.20629068064302, 41.27216340695391, 38.12353412062646, 24.454342631749157, 33.66332448350081, 46.84589576534266, 21.460708879265855, 31.604814607019975, 40.287274468323886, 28.989304827425798, 32.17826965904851, 40.726811762683816, 20.08109641680508, 40.018545321333946, 22.91728776897274, 44.804726409234455, 49.41740398361847, 40.42091716004104, 31.674040313035572, 27.141305709155407, 40.89389433957501, 25.530877874765675, 49.938867539860205, 39.91598203658789, 28.519999302863035, 32.953547828754864, 39.775294155500845, 40.16123171442461, 30.06494509027699, 46.13247717315336, 42.36194221841879, 26.346016931789073, 34.93330723476025, 28.13340175240209, 45.71374752513702, 23.715332525533015, 38.435830994309626, 29.486599589245863, 42.117627277894314, 46.67861948236036, 35.72551581181275, 41.615825527880176, 23.000421827646655, 21.653218319941104, 32.98952618843542, 24.81180608919692, 49.620462712219044, 36.532374455236905, 23.521408825116715, 37.37033619274201, 35.229066417222946, 41.66552071513209, 45.76332404695707, 47.003063930248544, 27.346684382602984, 25.820684468885773, 45.28564663506371, 21.096829568891895, 23.525769287109128, 26.734008152051317, 44.28094914467595, 31.191193317791367, 26.37303083882123, 24.34073418391033, 26.461946130297147, 39.89953772601966, 21.48046840365319, 40.0581754335774, 31.20533042467051, 40.52377184916453, 30.76985835018896, 34.30837675106465, 46.96883276681095, 43.89190296077969, 28.697403487758663, 48.91222985146058, 33.45107536693992, 42.894950226268456, 21.781495640173677, 41.749822821296405, 45.904119475807576, 48.34847576707279, 44.805848091460845, 39.332608441171985, 28.945620789891922, 30.430939659964732, 30.07932627020766, 46.74741460923275, 45.60818126888816, 45.62344655148689, 46.37520013062213, 43.69308841167229, 47.651572006124994, 30.828034179024137, 29.684886126442628, 21.221307874861065, 34.27478587571668, 27.33128217408365, 33.701108775814525, 26.941453386822367, 43.348285018893314, 30.50975556778699, 30.499785308905068, 36.0740575902307, 39.56373784526417, 47.349702674989295, 43.73682293057337, 35.79237617806087, 45.77007918974176, 46.87733576256963, 35.62033374447661, 40.133467231167174, 30.626744654817884, 35.778528157709644]}, {\"label\": \"optim_lr\", \"range\": [0.0003088223663359565, 0.0019966433265377016], \"values\": [0.0013600582845361532, 0.00164593256474053, 0.0014018921824870355, 0.0016585695591684302, 0.001213534490063318, 0.0010754555647681328, 0.0009570312679139653, 0.0004023833017697588, 0.0013333121368162954, 0.000655090485361219, 0.001359967171924176, 0.0009268327901236391, 0.001792928901290201, 0.0007807718363798963, 0.001861000292815646, 0.0004596988682893509, 0.0014001960383188444, 0.0017091980496695175, 0.001036589705369475, 0.0019196733195788744, 0.0010000942362402361, 0.001532932275693389, 0.0011072747761952015, 0.0010289067916078025, 0.0003571626589480145, 0.0010409703729515657, 0.0008989298240409062, 0.0013464512592825354, 0.0003564780549525014, 0.001958386558504906, 0.0008769864930641817, 0.0006806719697026463, 0.0011500447061398124, 0.0012105757651424292, 0.0006781534814575919, 0.0007324060190096681, 0.0013500184573629966, 0.0012121846588848278, 0.0005332747141652309, 0.0017127823739015238, 0.001455795075891508, 0.000731700792411544, 0.0015417517001635505, 0.0004998041551354563, 0.0017287285053102352, 0.001601052931471841, 0.00037754488315650697, 0.0018801998385467242, 0.0011710688876030366, 0.0006938927650010477, 0.001146838383362699, 0.0005518394636118806, 0.0009978366347605768, 0.0004663356236398579, 0.0009107614090021458, 0.00039082620903760297, 0.0007260586243296053, 0.0017629369955089497, 0.0011294887672782007, 0.000945875825030205, 0.0017403680482625428, 0.0009304497586704109, 0.0010981471149773877, 0.0003601161407843346, 0.0012166801156033797, 0.0012244701151314548, 0.0004588810759549995, 0.0013813037942601403, 0.0011558266274979195, 0.0016953041051922355, 0.0019138057046131193, 0.0019302706271679053, 0.0012116667254253879, 0.0008553914990060422, 0.0014047143549898709, 0.0003204615789260123, 0.0008271149879472146, 0.0016314985451334825, 0.0018756944520728625, 0.0010052566778670589, 0.0010634418270921925, 0.0008041456506088509, 0.000908782707695708, 0.0009443967233316286, 0.0008036120602309426, 0.0013777960861659235, 0.0005241484648770194, 0.0010097268371532203, 0.00033281103096682076, 0.0012385330703763506, 0.001504635025021787, 0.0018710699032552982, 0.0011711678198904484, 0.000648370267831493, 0.0017557150606170293, 0.0018675894850042284, 0.00031446970309626676, 0.0014423271390128982, 0.0017174909981840071, 0.0008677402783145756, 0.0016713378530331387, 0.00135200448601034, 0.0012216200710858953, 0.00036125748962856813, 0.0012861817524337615, 0.001048448379810136, 0.0011799405701744072, 0.0011991978793525013, 0.0003088223663359565, 0.00133232393581962, 0.0018779718084341573, 0.0008837659389445574, 0.0010618428142844985, 0.0015997553564081049, 0.0005333272958910355, 0.0004819070383294457, 0.0018160616411243592, 0.0017655064129470524, 0.0019743866239584048, 0.001965935954781926, 0.0006999468347406435, 0.0009785739469331143, 0.0014420503112285003, 0.0008457730830734688, 0.0014316521426971014, 0.0012093586533760427, 0.0017421782551769517, 0.0004450285693017958, 0.0006785184856926612, 0.0005607270923608878, 0.001017135680293566, 0.0017932332421459899, 0.0013919979739178833, 0.0007714784612189141, 0.0015696218319726182, 0.00152335426833189, 0.001006534043589938, 0.0007210645382369372, 0.001272134184816128, 0.0016461952683725326, 0.0015264311872417503, 0.0005364235919526418, 0.0016295519412840736, 0.0007191467976789655, 0.001883558557269749, 0.0009941149441775664, 0.0013203284556107427, 0.0017864798590272323, 0.0015345862112622162, 0.0006540305286065226, 0.000881633771432268, 0.00111495373396162, 0.0010763689085395434, 0.0015465915283384346, 0.0017829142668005825, 0.0011219808166266798, 0.0014793677112264394, 0.0017850466063943117, 0.0016763087491551217, 0.001543965115235918, 0.0014637396565504507, 0.0010502464993066983, 0.0010696390604491572, 0.0008919263026690843, 0.0018927773957595627, 0.0019668256278973116, 0.0019808733052575516, 0.001831975690103575, 0.0015601047260215837, 0.0011085014990442343, 0.0011719390492040866, 0.0008284279611436373, 0.000842159454937963, 0.0011161035092952846, 0.0016340419679101055, 0.001540706980399755, 0.0010550063957328409, 0.0008170950475617192, 0.0013044578348689337, 0.0016110832870420474, 0.0006916998927745956, 0.0013078964603279678, 0.0006036805852065862, 0.00048270336520696777, 0.0019966433265377016, 0.0013873578130383607, 0.0006950513623124808, 0.0019403723994423474, 0.0017957563682934287, 0.0003412635978575041, 0.00041255219319146364, 0.0006957135427078906, 0.0006897693597650727, 0.00038682831628773654, 0.00034756938497091083, 0.001957660956360479, 0.0007141599919235277, 0.0018525833795053175, 0.0004700045508923229, 0.0012391464002857763]}, {\"label\": \"optimizer\", \"range\": [0, 1], \"ticktext\": [[\"Yogi\", 0], [\"AdaMod\", 1]], \"tickvals\": [0, 1], \"values\": [0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1]}, {\"label\": \"smooth\", \"range\": [0.10016605464755113, 0.3498194984805427], \"values\": [0.2362207957492242, 0.16816407364502828, 0.11775901454947174, 0.31752181458960904, 0.25998025533188096, 0.14658308583169, 0.25302393068060536, 0.325587145793496, 0.13223157441371333, 0.3397373171561301, 0.21657769321407655, 0.29458637050647724, 0.12402460197349077, 0.10499691635218969, 0.17949579484849398, 0.2272422401667536, 0.2668525949909204, 0.23820536997189284, 0.28379850553064867, 0.2597302690578282, 0.17435923771378342, 0.34135405512998174, 0.20596376213954493, 0.19586555625873697, 0.24771819031204328, 0.13531597623147418, 0.12505672182807528, 0.10938984595703508, 0.2422751846536483, 0.11264702876355931, 0.28249764060601446, 0.14274664967078288, 0.10795973238282697, 0.16681563447036957, 0.19955526555402298, 0.3425591707740251, 0.2740858722038648, 0.21964908140468753, 0.2657695507750252, 0.26144614962547474, 0.2995117084781409, 0.15736045861776135, 0.15186751886027736, 0.30189506721469683, 0.19901492570182344, 0.28052016560068715, 0.23804811748060162, 0.11575957241734419, 0.24660254154658165, 0.1546007137029807, 0.25761198421669773, 0.3435646659643082, 0.2598681290996809, 0.13016424779652994, 0.32663887480529474, 0.3315532325440787, 0.13673666135009377, 0.2880336302469834, 0.11384358010529949, 0.313158730945585, 0.2742493104312468, 0.10242204269919897, 0.2999489711426545, 0.14352798805678307, 0.27034812765095945, 0.13235308435556284, 0.2810419091528858, 0.2790610435545047, 0.3397916507588056, 0.255419622689022, 0.25722460976542505, 0.28555949448292073, 0.146308081309046, 0.12300689640298931, 0.10390151611170706, 0.2927722620424912, 0.34758625039022345, 0.19202560049538353, 0.16151579624774112, 0.30563986284020295, 0.11150182772182424, 0.2742854042070887, 0.3377381527638485, 0.25778138539276435, 0.14296327476191076, 0.2388403157565437, 0.2748937650561878, 0.267976754069989, 0.32384647107205244, 0.15388220289113622, 0.16210336627074276, 0.2564091543359821, 0.21153387816480046, 0.3361768702241189, 0.23591951345702378, 0.1061318493085675, 0.18565274608539756, 0.1724439689801447, 0.25009805927440987, 0.2712729977626487, 0.22998809364270953, 0.3218162098656609, 0.225680190286331, 0.11074410214979724, 0.17500722986898237, 0.13646753851532473, 0.10990388064487944, 0.1468879838894723, 0.2176622373034774, 0.1500910804852985, 0.22862818582468916, 0.18862651343793413, 0.3498194984805427, 0.24101609008348293, 0.11565900076495245, 0.20831968321897176, 0.3339580200541971, 0.14726566496633356, 0.1603892600099796, 0.21993846754926955, 0.16781301919046604, 0.1999168430253619, 0.30560168458892256, 0.29395080470549606, 0.25157703326127123, 0.32282858757151334, 0.14764172873501702, 0.17684402927855403, 0.11653736552923868, 0.32123797322885983, 0.1873600730121337, 0.12390497064696399, 0.19113615649919663, 0.15012900322999795, 0.11170158867804719, 0.27159051239843757, 0.23737514319881783, 0.20648648627360044, 0.2111468219528252, 0.3238362784798209, 0.14151195613031142, 0.23386706420077932, 0.1256034396131041, 0.31943769709806435, 0.3331403009643351, 0.10186707943622972, 0.338583453848173, 0.214221161768902, 0.20075650060107214, 0.116108861311439, 0.30072334289033353, 0.23865084724861857, 0.27876314936629176, 0.24720292739995503, 0.3222649882974321, 0.3213018185962099, 0.33082632688967706, 0.16340642693809537, 0.23316714686784015, 0.174566105222275, 0.2947948583254585, 0.349359031889486, 0.25529231184176365, 0.3221538737618152, 0.3296366127975875, 0.2870559920684942, 0.19197937195446835, 0.2411666338983283, 0.1096393115147496, 0.28187018502453887, 0.1825667589242248, 0.2827663022936009, 0.30379984882857836, 0.2101942981509597, 0.1550259651952266, 0.341272346084163, 0.14412484722226504, 0.11889164054812498, 0.28098534962533145, 0.20870665910436836, 0.22671573962182834, 0.24699178128902077, 0.11099385800602266, 0.15582291741356202, 0.2029038784034397, 0.286025307738222, 0.2226049771090688, 0.11818852116139764, 0.16632583113426186, 0.18152942308698522, 0.2188311955530206, 0.2692611348325715, 0.2395128091643156, 0.30805971526222486, 0.10016605464755113, 0.19949703936399815, 0.2936252387210505, 0.19824169371436468, 0.288725276034392, 0.3388876371366121]}], \"line\": {\"color\": [0.87, 0.845, 0.835, 0.84, 0.85, 0.835, 0.81, 0.83, 0.8, 0.83, 0.825, 0.875, 0.845, 0.84, 0.83, 0.845, 0.83, 0.85, 0.85, 0.845, 0.835, 0.805, 0.84, 0.83, 0.85, 0.815, 0.82, 0.835, 0.825, 0.835, 0.815, 0.85, 0.845, 0.81, 0.85, 0.845, 0.83, 0.825, 0.835, 0.805, 0.855, 0.82, 0.845, 0.865, 0.825, 0.815, 0.84, 0.825, 0.84, 0.81, 0.825, 0.835, 0.835, 0.82, 0.87, 0.83, 0.845, 0.825, 0.845, 0.805, 0.84, 0.83, 0.805, 0.84, 0.84, 0.855, 0.805, 0.82, 0.815, 0.83, 0.82, 0.855, 0.82, 0.84, 0.82, 0.815, 0.845, 0.83, 0.815, 0.825, 0.81, 0.855, 0.84, 0.835, 0.83, 0.845, 0.84, 0.83, 0.865, 0.82, 0.825, 0.82, 0.825, 0.825, 0.84, 0.795, 0.845, 0.82, 0.835, 0.84, 0.84, 0.835, 0.81, 0.845, 0.855, 0.845, 0.83, 0.825, 0.82, 0.835, 0.835, 0.815, 0.85, 0.835, 0.85, 0.845, 0.86, 0.82, 0.84, 0.8, 0.815, 0.835, 0.83, 0.805, 0.83, 0.855, 0.84, 0.83, 0.805, 0.785, 0.84, 0.83, 0.82, 0.84, 0.835, 0.83, 0.85, 0.815, 0.845, 0.835, 0.855, 0.81, 0.84, 0.81, 0.84, 0.835, 0.835, 0.84, 0.845, 0.815, 0.83, 0.85, 0.835, 0.8, 0.84, 0.83, 0.805, 0.855, 0.81, 0.84, 0.81, 0.84, 0.83, 0.84, 0.835, 0.82, 0.855, 0.825, 0.815, 0.83, 0.86, 0.83, 0.84, 0.825, 0.845, 0.855, 0.815, 0.83, 0.835, 0.805, 0.85, 0.84, 0.845, 0.81, 0.8, 0.85, 0.87, 0.785, 0.79, 0.8, 0.84, 0.835, 0.835, 0.845, 0.81, 0.835, 0.84, 0.825, 0.855, 0.86], \"colorbar\": {\"title\": {\"text\": \"Objective Value\"}}, \"colorscale\": [[0.0, \"rgb(247,251,255)\"], [0.125, \"rgb(222,235,247)\"], [0.25, \"rgb(198,219,239)\"], [0.375, \"rgb(158,202,225)\"], [0.5, \"rgb(107,174,214)\"], [0.625, \"rgb(66,146,198)\"], [0.75, \"rgb(33,113,181)\"], [0.875, \"rgb(8,81,156)\"], [1.0, \"rgb(8,48,107)\"]], \"reversescale\": false, \"showscale\": true}, \"type\": \"parcoords\"}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Parallel Coordinate Plot\"}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('3abb5360-d6ab-46bc-9217-4e0035aac4bb');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-ZfIleCESXH",
        "colab_type": "text"
      },
      "source": [
        "# Testando a melhor configuração encontrada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxciBKMAbASr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "5b948fab-1aa0-45dd-f1cf-d7584463afcc"
      },
      "source": [
        "# Melhor params dict\n",
        "study.best_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'drop': 0.358600871034648,\n",
              " 'h1_units': 70.14022844516676,\n",
              " 'h2_units': 40.242569667770624,\n",
              " 'optim_lr': 0.0009268327901236391,\n",
              " 'optimizer': 'Yogi',\n",
              " 'smooth': 0.29458637050647724}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eKA4znXZbVuW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "05f10a76-dee9-43aa-ed30-fc721596899b"
      },
      "source": [
        "deterministic() \n",
        "\n",
        "# Configura o melhor setup encontrado pelo Optuna\n",
        "H1     = int(study.best_params['h1_units'])\n",
        "H2     = int(study.best_params['h2_units'])\n",
        "D      = study.best_params['drop']\n",
        "SMOOTH = study.best_params['smooth']\n",
        "LR     = study.best_params['optim_lr']\n",
        "\n",
        "model = MLP(VOCAB_SIZE, H1, 39, D, O).to(device)\n",
        "model.apply(weights_init)    \n",
        "criterion = LabelSmoothing(SMOOTH)\n",
        "\n",
        "if study.best_params['optimizer'] == 'Yogi':\n",
        "  print(f'Using {study.best_params[\"optimizer\"]}')\n",
        "  optimizer = optim.Yogi(model.parameters(),lr= LR)  \n",
        "else:\n",
        "  print(f'Using {study.best_params[\"optimizer\"]}')\n",
        "  optimizer = optim.AdaMod(model.parameters(),lr= LR)  \n",
        "\n",
        "print(model)\n",
        "\n",
        "# Count params\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'\\n################################################\\\n",
        "       \\n# The model has {count_parameters(model):,} trainable parameters #\\\n",
        "       \\n################################################')  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deterministic experiment, seed: 0\n",
            "Using Yogi\n",
            "MLP(\n",
            "  (norm0): LayerNorm((17299,), eps=1e-05, elementwise_affine=True)\n",
            "  (drop): Dropout(p=0.358600871034648, inplace=False)\n",
            "  (relu): ReLU()\n",
            "  (fc0): Linear(in_features=17299, out_features=70, bias=True)\n",
            "  (fc1): Linear(in_features=70, out_features=39, bias=True)\n",
            "  (fc2): Linear(in_features=39, out_features=2, bias=True)\n",
            ")\n",
            "\n",
            "################################################       \n",
            "# The model has 1,248,447 trainable parameters #       \n",
            "################################################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qWN-RKyIYAy5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "f6ed8c49-6955-4cb3-a338-ded02bedbaa4"
      },
      "source": [
        "%%time\n",
        "import os\n",
        "deterministic() \n",
        "\n",
        "N_EPOCHS = 100\n",
        "epoch, best_acc = 0,0\n",
        "\n",
        "for step in range(1, N_EPOCHS+1):\n",
        "  loss_train, ppl_train = train(model, device, train_loader_bow, criterion, optimizer)\n",
        "  loss_valid, ppl_valid, acc = test(model, device, valid_loader_bow, criterion)\n",
        "  if acc >= best_acc:\n",
        "    best_acc = acc\n",
        "    epoch    = step\n",
        "    print(f'Epoch [{step}/{N_EPOCHS}] | Train Loss: {loss_train:.3f} -- Valid Loss: {loss_valid:.3f} --',end=' ')\n",
        "    print(f'Acc: {acc:.3f}')\n",
        "    print(f'Ppl train: {ppl_train:.3f} -- Ppl valid: {ppl_valid:.3f}\\n')\n",
        "   \n",
        "print(f'\\nEnd of training. Best Acc: -->[{best_acc:.4f}]<--, at epoch: {epoch}\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deterministic experiment, seed: 0\n",
            "Epoch [1/100] | Train Loss: 0.664 -- Valid Loss: 0.585 -- Acc: 0.780\n",
            "Ppl train: 1.943 -- Ppl valid: 1.795\n",
            "\n",
            "Epoch [2/100] | Train Loss: 0.502 -- Valid Loss: 0.558 -- Acc: 0.815\n",
            "Ppl train: 1.653 -- Ppl valid: 1.747\n",
            "\n",
            "Epoch [3/100] | Train Loss: 0.478 -- Valid Loss: 0.564 -- Acc: 0.835\n",
            "Ppl train: 1.613 -- Ppl valid: 1.758\n",
            "\n",
            "Epoch [4/100] | Train Loss: 0.473 -- Valid Loss: 0.575 -- Acc: 0.850\n",
            "Ppl train: 1.604 -- Ppl valid: 1.777\n",
            "\n",
            "Epoch [10/100] | Train Loss: 0.447 -- Valid Loss: 0.566 -- Acc: 0.850\n",
            "Ppl train: 1.563 -- Ppl valid: 1.762\n",
            "\n",
            "Epoch [11/100] | Train Loss: 0.448 -- Valid Loss: 0.569 -- Acc: 0.855\n",
            "Ppl train: 1.565 -- Ppl valid: 1.767\n",
            "\n",
            "Epoch [12/100] | Train Loss: 0.445 -- Valid Loss: 0.570 -- Acc: 0.860\n",
            "Ppl train: 1.560 -- Ppl valid: 1.769\n",
            "\n",
            "Epoch [13/100] | Train Loss: 0.443 -- Valid Loss: 0.571 -- Acc: 0.860\n",
            "Ppl train: 1.557 -- Ppl valid: 1.770\n",
            "\n",
            "Epoch [20/100] | Train Loss: 0.438 -- Valid Loss: 0.570 -- Acc: 0.880\n",
            "Ppl train: 1.549 -- Ppl valid: 1.769\n",
            "\n",
            "\n",
            "End of training. Best Acc: -->[0.8800]<--, at epoch: 20\n",
            "\n",
            "CPU times: user 13.5 s, sys: 888 ms, total: 14.4 s\n",
            "Wall time: 14.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYEkdNJQbcOc",
        "colab_type": "text"
      },
      "source": [
        "# Implementação com Embeddings glove"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8jxHv06bcKx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "20f1281f-cbf6-47ab-cb34-1ad68f089540"
      },
      "source": [
        "set_vocabulary = set() # palavras únicas \n",
        "for review in tokenized_processed:\n",
        "  for word in review:\n",
        "    set_vocabulary.add(word)\n",
        "\n",
        "vocab_set_size = len(set_vocabulary) # conj. de words do vocab\n",
        "\n",
        "print(f'Set vocab size: {vocab_set_size} words') # tamanho do vocab do IMDB"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Set vocab size: 19734 words\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAPu3HwpbcHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dict word2idx\n",
        "idx = 0\n",
        "word_to_idx = {} # dict {word:number}\n",
        "for word in set_vocabulary:\n",
        "  word_to_idx[word] = idx\n",
        "  idx += 1\n",
        "\n",
        "# dict idx to word\n",
        "idx_to_word = {value: key for key, value in iter(word_to_idx.items())} #dict {number:word}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WChWEUi1bnFj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cria a lista de índices das sequências de cada review\n",
        "sequence_reviews = []\n",
        "for review in tokenized_processed:\n",
        "  word_seq = []\n",
        "  for word in review:\n",
        "    word_seq.append(word_to_idx[word])\n",
        "  sequence_reviews.append(word_seq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1cfZKdtmxNq",
        "colab_type": "text"
      },
      "source": [
        "## Download glove"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgS2W7SCbpjv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9adde378-43f8-486c-f20a-a7d1120462cc"
      },
      "source": [
        "import torchtext.vocab\n",
        "\n",
        "# glove\n",
        "glove = torchtext.vocab.GloVe(name = '6B', dim = 300)\n",
        "print(f'There are {len(glove.itos)} words in the vocabulary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:26, 2.23MB/s]                          \n",
            "100%|█████████▉| 399670/400000 [00:38<00:00, 10172.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "There are 400000 words in the vocabulary\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2xX2HREbm_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb_dim = glove.vectors.shape[1] # dim do emb = 300 = dim do emb. do glove\n",
        "emb     = np.zeros((vocab_set_size, emb_dim)) # cria um array de zeros"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6h2H4vYbm9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mapeia os embeddings do glove nas palavras do dataset IMDB\n",
        "for num in range(1, len(emb)):\n",
        "  word = idx_to_word[num]\n",
        "  if word and re.match(r\"^[a-zA-Z0-9\\-]*$\", word) and word in glove.stoi.keys(): \n",
        "    temp_idx = glove.stoi[word] # pega o idx da palavra no glove.stoi dict\n",
        "    emb[num] = glove.vectors[temp_idx] \n",
        "  else: # o else é para o caso se não existir a palavra no glove e evitar uma quebra\n",
        "    emb[num] = np.random.normal(size=(emb_dim,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUP8Ti-FtZGY",
        "colab_type": "text"
      },
      "source": [
        "## Com a soma dos Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAOCjpT3MdER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Somando os embeddings de cada review \n",
        "dataset_sum = []\n",
        "for review in sequence_reviews:\n",
        "  word_sum = np.zeros(emb_dim)\n",
        "  for idx in review:\n",
        "    word_sum += emb[idx]\n",
        "  dataset_sum.append(word_sum)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlsRxsELtcZO",
        "colab_type": "text"
      },
      "source": [
        "## Com a média dos Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLw8n8NttI_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fazendo a média dos embedding de cada review\n",
        "dataset_mean = []\n",
        "for review in sequence_reviews:\n",
        "  word_mean = np.zeros(emb_dim)\n",
        "  for idx in review:\n",
        "    word_mean += emb[idx]\n",
        "  dataset_mean.append(word_mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojbQevjcMdBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split do dado em train=80% e test=20%\n",
        "X_train_emb, X_test_emb, y_train_emb, y_test_emb = train_test_split(dataset_mean, \n",
        "                                                                    labels, \n",
        "                                                                    test_size=0.2, \n",
        "                                                                    random_state=123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BCOES_t7e64M",
        "colab": {}
      },
      "source": [
        "# Cria o dataset (Pandas DF) de treino\n",
        "df_train_emb = pd.DataFrame(X_train_emb)\n",
        "df_train_emb['label'] = y_train_emb\n",
        "cols = df_train_emb.columns.tolist()\n",
        "cols = cols[-1:] + cols[:-1]\n",
        "df_train_emb = df_train_emb[cols]\n",
        "\n",
        "# Cria o dataset (Pandas DF) de teste\n",
        "df_test_emb = pd.DataFrame(X_test_emb)\n",
        "df_test_emb['label'] = y_test_emb\n",
        "cols = df_test_emb.columns.tolist()\n",
        "cols = cols[-1:] + cols[:-1]\n",
        "df_test_emb = df_test_emb[cols]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q5NTUmxpe64S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "43d9d4cb-4aba-4556-8f42-12127fcef7c9"
      },
      "source": [
        "# Salva em CSV (não é a melhor forma de fazer, mas qdo o colab quebra é mais rápido de reiniciar)\n",
        "df_train_emb.to_csv('train_emb.csv')\n",
        "df_test_emb.to_csv('test_emb.csv')\n",
        "\n",
        "df_train_emb = pd.read_csv('train_emb.csv',index_col=0)\n",
        "df_test_emb  = pd.read_csv('test_emb.csv', index_col=0)\n",
        "\n",
        "print(f'df_train_emb.shape: {df_train_emb.shape}') \n",
        "print(f'df_test_emb.shape: {df_test_emb.shape}') \n",
        "\n",
        "# teste de sanidade:\n",
        "trn = pd.read_csv('train_emb.csv', index_col=0)\n",
        "trn.head() # é 301 com a coluna label"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df_train_emb.shape: (800, 301)\n",
            "df_test_emb.shape: (200, 301)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>260</th>\n",
              "      <th>261</th>\n",
              "      <th>262</th>\n",
              "      <th>263</th>\n",
              "      <th>264</th>\n",
              "      <th>265</th>\n",
              "      <th>266</th>\n",
              "      <th>267</th>\n",
              "      <th>268</th>\n",
              "      <th>269</th>\n",
              "      <th>270</th>\n",
              "      <th>271</th>\n",
              "      <th>272</th>\n",
              "      <th>273</th>\n",
              "      <th>274</th>\n",
              "      <th>275</th>\n",
              "      <th>276</th>\n",
              "      <th>277</th>\n",
              "      <th>278</th>\n",
              "      <th>279</th>\n",
              "      <th>280</th>\n",
              "      <th>281</th>\n",
              "      <th>282</th>\n",
              "      <th>283</th>\n",
              "      <th>284</th>\n",
              "      <th>285</th>\n",
              "      <th>286</th>\n",
              "      <th>287</th>\n",
              "      <th>288</th>\n",
              "      <th>289</th>\n",
              "      <th>290</th>\n",
              "      <th>291</th>\n",
              "      <th>292</th>\n",
              "      <th>293</th>\n",
              "      <th>294</th>\n",
              "      <th>295</th>\n",
              "      <th>296</th>\n",
              "      <th>297</th>\n",
              "      <th>298</th>\n",
              "      <th>299</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.175189</td>\n",
              "      <td>7.890260</td>\n",
              "      <td>-3.335603</td>\n",
              "      <td>-0.623612</td>\n",
              "      <td>-0.493672</td>\n",
              "      <td>4.780501</td>\n",
              "      <td>-1.118976</td>\n",
              "      <td>8.345500</td>\n",
              "      <td>-0.268218</td>\n",
              "      <td>-98.652219</td>\n",
              "      <td>8.308585</td>\n",
              "      <td>-0.845498</td>\n",
              "      <td>-6.968584</td>\n",
              "      <td>10.715902</td>\n",
              "      <td>-5.349379</td>\n",
              "      <td>-17.695685</td>\n",
              "      <td>-11.697952</td>\n",
              "      <td>-4.637259</td>\n",
              "      <td>9.044115</td>\n",
              "      <td>9.437877</td>\n",
              "      <td>13.441528</td>\n",
              "      <td>25.621982</td>\n",
              "      <td>13.948138</td>\n",
              "      <td>0.598330</td>\n",
              "      <td>-7.811959</td>\n",
              "      <td>8.302181</td>\n",
              "      <td>10.292526</td>\n",
              "      <td>-14.561384</td>\n",
              "      <td>7.036685</td>\n",
              "      <td>6.564113</td>\n",
              "      <td>-8.189259</td>\n",
              "      <td>14.378858</td>\n",
              "      <td>-25.205401</td>\n",
              "      <td>-13.822574</td>\n",
              "      <td>-65.980924</td>\n",
              "      <td>8.450704</td>\n",
              "      <td>-10.228753</td>\n",
              "      <td>3.127133</td>\n",
              "      <td>1.861251</td>\n",
              "      <td>...</td>\n",
              "      <td>2.753446</td>\n",
              "      <td>-8.488267</td>\n",
              "      <td>-6.017050</td>\n",
              "      <td>-5.913927</td>\n",
              "      <td>-0.800698</td>\n",
              "      <td>5.500927</td>\n",
              "      <td>-7.506946</td>\n",
              "      <td>-10.436810</td>\n",
              "      <td>7.356865</td>\n",
              "      <td>19.226468</td>\n",
              "      <td>8.580069</td>\n",
              "      <td>-5.825167</td>\n",
              "      <td>8.854994</td>\n",
              "      <td>0.014664</td>\n",
              "      <td>12.343413</td>\n",
              "      <td>13.278913</td>\n",
              "      <td>-118.768193</td>\n",
              "      <td>-0.553934</td>\n",
              "      <td>15.648481</td>\n",
              "      <td>-10.788418</td>\n",
              "      <td>-6.889231</td>\n",
              "      <td>1.847679</td>\n",
              "      <td>3.200727</td>\n",
              "      <td>4.155577</td>\n",
              "      <td>2.368402</td>\n",
              "      <td>5.161657</td>\n",
              "      <td>7.243918</td>\n",
              "      <td>2.182981</td>\n",
              "      <td>-7.676454</td>\n",
              "      <td>-0.832201</td>\n",
              "      <td>3.753030</td>\n",
              "      <td>-6.959814</td>\n",
              "      <td>-6.064977</td>\n",
              "      <td>1.756640</td>\n",
              "      <td>1.869142</td>\n",
              "      <td>-26.796490</td>\n",
              "      <td>4.293049</td>\n",
              "      <td>1.092765</td>\n",
              "      <td>-1.346390</td>\n",
              "      <td>5.564341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>-3.325124</td>\n",
              "      <td>4.122604</td>\n",
              "      <td>-2.091796</td>\n",
              "      <td>1.704440</td>\n",
              "      <td>-1.080098</td>\n",
              "      <td>0.007943</td>\n",
              "      <td>0.703317</td>\n",
              "      <td>2.217407</td>\n",
              "      <td>2.019190</td>\n",
              "      <td>-44.418174</td>\n",
              "      <td>6.173046</td>\n",
              "      <td>-0.687947</td>\n",
              "      <td>-1.658936</td>\n",
              "      <td>7.832602</td>\n",
              "      <td>1.310181</td>\n",
              "      <td>-3.749725</td>\n",
              "      <td>0.999754</td>\n",
              "      <td>-1.707927</td>\n",
              "      <td>6.429207</td>\n",
              "      <td>9.140724</td>\n",
              "      <td>10.182271</td>\n",
              "      <td>11.903065</td>\n",
              "      <td>3.162164</td>\n",
              "      <td>-0.072153</td>\n",
              "      <td>-6.980918</td>\n",
              "      <td>0.312659</td>\n",
              "      <td>3.052520</td>\n",
              "      <td>-7.473797</td>\n",
              "      <td>4.266604</td>\n",
              "      <td>4.918511</td>\n",
              "      <td>-8.362916</td>\n",
              "      <td>4.045189</td>\n",
              "      <td>-8.796783</td>\n",
              "      <td>0.054594</td>\n",
              "      <td>-41.645077</td>\n",
              "      <td>5.693744</td>\n",
              "      <td>-6.617915</td>\n",
              "      <td>0.344042</td>\n",
              "      <td>1.879002</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.010542</td>\n",
              "      <td>-5.018574</td>\n",
              "      <td>0.353384</td>\n",
              "      <td>-3.930324</td>\n",
              "      <td>-1.776730</td>\n",
              "      <td>-1.839825</td>\n",
              "      <td>0.149257</td>\n",
              "      <td>-6.029155</td>\n",
              "      <td>1.750806</td>\n",
              "      <td>10.972487</td>\n",
              "      <td>4.623418</td>\n",
              "      <td>-6.995084</td>\n",
              "      <td>3.743650</td>\n",
              "      <td>-5.144257</td>\n",
              "      <td>5.060139</td>\n",
              "      <td>-0.337170</td>\n",
              "      <td>-66.040384</td>\n",
              "      <td>5.978527</td>\n",
              "      <td>2.000124</td>\n",
              "      <td>-3.143935</td>\n",
              "      <td>-11.692010</td>\n",
              "      <td>3.664508</td>\n",
              "      <td>-0.363919</td>\n",
              "      <td>-3.321573</td>\n",
              "      <td>-3.314130</td>\n",
              "      <td>8.388756</td>\n",
              "      <td>4.152227</td>\n",
              "      <td>-1.471174</td>\n",
              "      <td>-2.609580</td>\n",
              "      <td>-6.410495</td>\n",
              "      <td>3.361549</td>\n",
              "      <td>-1.065244</td>\n",
              "      <td>-5.592382</td>\n",
              "      <td>2.081049</td>\n",
              "      <td>-5.998598</td>\n",
              "      <td>-19.252952</td>\n",
              "      <td>-1.710061</td>\n",
              "      <td>1.636862</td>\n",
              "      <td>1.525938</td>\n",
              "      <td>6.032985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>-5.968698</td>\n",
              "      <td>6.109819</td>\n",
              "      <td>1.351162</td>\n",
              "      <td>-2.166283</td>\n",
              "      <td>4.843036</td>\n",
              "      <td>6.535433</td>\n",
              "      <td>-5.611836</td>\n",
              "      <td>3.233865</td>\n",
              "      <td>0.358069</td>\n",
              "      <td>-62.947103</td>\n",
              "      <td>3.532420</td>\n",
              "      <td>-1.483208</td>\n",
              "      <td>-2.571186</td>\n",
              "      <td>8.016742</td>\n",
              "      <td>-0.031484</td>\n",
              "      <td>-8.584871</td>\n",
              "      <td>-7.260515</td>\n",
              "      <td>1.360762</td>\n",
              "      <td>5.496764</td>\n",
              "      <td>5.736401</td>\n",
              "      <td>1.729584</td>\n",
              "      <td>14.500372</td>\n",
              "      <td>6.956912</td>\n",
              "      <td>5.355796</td>\n",
              "      <td>-5.028713</td>\n",
              "      <td>-1.131714</td>\n",
              "      <td>1.849990</td>\n",
              "      <td>-11.602456</td>\n",
              "      <td>8.685791</td>\n",
              "      <td>1.473613</td>\n",
              "      <td>-11.861843</td>\n",
              "      <td>11.891792</td>\n",
              "      <td>-8.586375</td>\n",
              "      <td>-4.980456</td>\n",
              "      <td>-39.153563</td>\n",
              "      <td>8.998899</td>\n",
              "      <td>-11.264067</td>\n",
              "      <td>-2.856228</td>\n",
              "      <td>-10.338615</td>\n",
              "      <td>...</td>\n",
              "      <td>5.190274</td>\n",
              "      <td>-2.366938</td>\n",
              "      <td>3.234602</td>\n",
              "      <td>1.656442</td>\n",
              "      <td>-3.229141</td>\n",
              "      <td>1.955247</td>\n",
              "      <td>-4.027668</td>\n",
              "      <td>-0.000716</td>\n",
              "      <td>0.010369</td>\n",
              "      <td>12.054717</td>\n",
              "      <td>0.500569</td>\n",
              "      <td>-4.295453</td>\n",
              "      <td>3.741223</td>\n",
              "      <td>6.252916</td>\n",
              "      <td>1.102212</td>\n",
              "      <td>-1.715822</td>\n",
              "      <td>-81.925333</td>\n",
              "      <td>-6.589124</td>\n",
              "      <td>-0.501309</td>\n",
              "      <td>-9.921314</td>\n",
              "      <td>-6.507059</td>\n",
              "      <td>-0.031098</td>\n",
              "      <td>0.422608</td>\n",
              "      <td>4.592097</td>\n",
              "      <td>-3.507558</td>\n",
              "      <td>13.131541</td>\n",
              "      <td>6.127293</td>\n",
              "      <td>-2.404148</td>\n",
              "      <td>-2.429493</td>\n",
              "      <td>2.500425</td>\n",
              "      <td>-1.493398</td>\n",
              "      <td>-4.286826</td>\n",
              "      <td>-5.707399</td>\n",
              "      <td>-1.993366</td>\n",
              "      <td>3.552865</td>\n",
              "      <td>-19.591845</td>\n",
              "      <td>2.992214</td>\n",
              "      <td>4.690124</td>\n",
              "      <td>1.108768</td>\n",
              "      <td>-0.307468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>-17.704013</td>\n",
              "      <td>3.248839</td>\n",
              "      <td>-0.463489</td>\n",
              "      <td>0.066741</td>\n",
              "      <td>-0.445604</td>\n",
              "      <td>15.513841</td>\n",
              "      <td>-10.339036</td>\n",
              "      <td>6.232302</td>\n",
              "      <td>9.599130</td>\n",
              "      <td>-125.177975</td>\n",
              "      <td>5.502706</td>\n",
              "      <td>-4.742642</td>\n",
              "      <td>-4.669554</td>\n",
              "      <td>12.887255</td>\n",
              "      <td>-3.463090</td>\n",
              "      <td>-13.335997</td>\n",
              "      <td>-1.455440</td>\n",
              "      <td>-13.085422</td>\n",
              "      <td>16.931981</td>\n",
              "      <td>3.123546</td>\n",
              "      <td>14.102994</td>\n",
              "      <td>28.188383</td>\n",
              "      <td>7.255666</td>\n",
              "      <td>25.189019</td>\n",
              "      <td>-12.698952</td>\n",
              "      <td>1.831850</td>\n",
              "      <td>5.090850</td>\n",
              "      <td>-22.527845</td>\n",
              "      <td>8.152490</td>\n",
              "      <td>-5.361577</td>\n",
              "      <td>-13.652625</td>\n",
              "      <td>22.837091</td>\n",
              "      <td>-23.505551</td>\n",
              "      <td>-4.957126</td>\n",
              "      <td>-107.178161</td>\n",
              "      <td>24.194266</td>\n",
              "      <td>-11.464290</td>\n",
              "      <td>11.265455</td>\n",
              "      <td>-8.820877</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.304915</td>\n",
              "      <td>-7.171077</td>\n",
              "      <td>2.200216</td>\n",
              "      <td>-7.830466</td>\n",
              "      <td>-5.492378</td>\n",
              "      <td>2.728261</td>\n",
              "      <td>10.374815</td>\n",
              "      <td>-16.043465</td>\n",
              "      <td>16.735035</td>\n",
              "      <td>17.944590</td>\n",
              "      <td>6.383995</td>\n",
              "      <td>-8.103817</td>\n",
              "      <td>13.288826</td>\n",
              "      <td>-7.609929</td>\n",
              "      <td>9.301858</td>\n",
              "      <td>3.795162</td>\n",
              "      <td>-164.076881</td>\n",
              "      <td>-5.323981</td>\n",
              "      <td>9.549318</td>\n",
              "      <td>-5.404796</td>\n",
              "      <td>-14.969718</td>\n",
              "      <td>9.098634</td>\n",
              "      <td>-4.858930</td>\n",
              "      <td>0.003711</td>\n",
              "      <td>1.193812</td>\n",
              "      <td>16.437293</td>\n",
              "      <td>4.389677</td>\n",
              "      <td>3.538050</td>\n",
              "      <td>-5.429608</td>\n",
              "      <td>-5.157111</td>\n",
              "      <td>0.036722</td>\n",
              "      <td>-5.656491</td>\n",
              "      <td>-16.752154</td>\n",
              "      <td>6.048390</td>\n",
              "      <td>-2.379699</td>\n",
              "      <td>-28.599964</td>\n",
              "      <td>-4.505762</td>\n",
              "      <td>3.603978</td>\n",
              "      <td>-0.296623</td>\n",
              "      <td>-3.579694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>-40.989377</td>\n",
              "      <td>16.946282</td>\n",
              "      <td>-8.290026</td>\n",
              "      <td>-35.707902</td>\n",
              "      <td>-19.382237</td>\n",
              "      <td>22.271054</td>\n",
              "      <td>-22.587023</td>\n",
              "      <td>-7.844867</td>\n",
              "      <td>-13.060309</td>\n",
              "      <td>-234.151581</td>\n",
              "      <td>24.195289</td>\n",
              "      <td>4.870549</td>\n",
              "      <td>-27.473166</td>\n",
              "      <td>38.165710</td>\n",
              "      <td>11.335514</td>\n",
              "      <td>-21.844541</td>\n",
              "      <td>-6.554400</td>\n",
              "      <td>-20.044815</td>\n",
              "      <td>16.002340</td>\n",
              "      <td>13.515200</td>\n",
              "      <td>-9.192250</td>\n",
              "      <td>73.277540</td>\n",
              "      <td>26.322499</td>\n",
              "      <td>42.987998</td>\n",
              "      <td>-7.809791</td>\n",
              "      <td>36.099974</td>\n",
              "      <td>28.650725</td>\n",
              "      <td>-66.885000</td>\n",
              "      <td>-13.823741</td>\n",
              "      <td>66.031858</td>\n",
              "      <td>-27.130183</td>\n",
              "      <td>5.486564</td>\n",
              "      <td>-32.281351</td>\n",
              "      <td>-14.962282</td>\n",
              "      <td>-155.546311</td>\n",
              "      <td>25.804761</td>\n",
              "      <td>-14.836090</td>\n",
              "      <td>5.357022</td>\n",
              "      <td>39.215412</td>\n",
              "      <td>...</td>\n",
              "      <td>-9.817915</td>\n",
              "      <td>-19.974135</td>\n",
              "      <td>21.979366</td>\n",
              "      <td>5.247863</td>\n",
              "      <td>-19.254807</td>\n",
              "      <td>3.890525</td>\n",
              "      <td>-11.310593</td>\n",
              "      <td>-9.602268</td>\n",
              "      <td>10.451536</td>\n",
              "      <td>44.334368</td>\n",
              "      <td>37.786378</td>\n",
              "      <td>9.463019</td>\n",
              "      <td>-5.907602</td>\n",
              "      <td>-0.546631</td>\n",
              "      <td>26.048824</td>\n",
              "      <td>23.763076</td>\n",
              "      <td>-336.446495</td>\n",
              "      <td>-43.303972</td>\n",
              "      <td>2.507436</td>\n",
              "      <td>-27.934324</td>\n",
              "      <td>-18.077321</td>\n",
              "      <td>18.578199</td>\n",
              "      <td>-1.633587</td>\n",
              "      <td>18.766740</td>\n",
              "      <td>-10.112308</td>\n",
              "      <td>47.196924</td>\n",
              "      <td>-21.712629</td>\n",
              "      <td>47.335789</td>\n",
              "      <td>-31.958048</td>\n",
              "      <td>-15.132986</td>\n",
              "      <td>-9.315146</td>\n",
              "      <td>-12.108823</td>\n",
              "      <td>11.845148</td>\n",
              "      <td>22.100669</td>\n",
              "      <td>15.953262</td>\n",
              "      <td>-15.289622</td>\n",
              "      <td>-5.795462</td>\n",
              "      <td>-2.927339</td>\n",
              "      <td>-0.642241</td>\n",
              "      <td>2.319307</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 301 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label          0          1  ...       297       298       299\n",
              "0      0  -1.175189   7.890260  ...  1.092765 -1.346390  5.564341\n",
              "1      0  -3.325124   4.122604  ...  1.636862  1.525938  6.032985\n",
              "2      0  -5.968698   6.109819  ...  4.690124  1.108768 -0.307468\n",
              "3      0 -17.704013   3.248839  ...  3.603978 -0.296623 -3.579694\n",
              "4      1 -40.989377  16.946282  ... -2.927339 -0.642241  2.319307\n",
              "\n",
              "[5 rows x 301 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jBFOazOGgGp4"
      },
      "source": [
        "## Dataloaders, Minibatches and Criterion\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bu3YK4pygGp8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "40545d49-bbe4-43f9-a14c-47e5e0c5a5e4"
      },
      "source": [
        "BATCH_SIZE = 20\n",
        "\n",
        "# Cria datasets de TREINO e VALID\n",
        "dataset_train  = ImdbDataset('train_emb.csv')\n",
        "dataset_valid  = ImdbDataset('test_emb.csv')\n",
        "\n",
        "# Cria dataloader das médias (ou sum) dos embeddings -  TREINO\n",
        "train_loader_emb = DataLoader(dataset=dataset_train, \n",
        "                              batch_size=BATCH_SIZE, \n",
        "                              shuffle=True)\n",
        "\n",
        "# Cria dataloader das médias (ou sum) dos embeddings -  VALID\n",
        "valid_loader_emb = DataLoader(dataset=dataset_valid, \n",
        "                              batch_size=BATCH_SIZE, \n",
        "                              shuffle=False)                       \n",
        "\n",
        "print(len(train_loader_emb), len(valid_loader_emb))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "id-aWj65zqMr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "68af2cc3-da38-4624-f749-f9e63b80192c"
      },
      "source": [
        "a = nn.Parameter(torch.randn(BATCH_SIZE, 300).type(torch.FloatTensor))\n",
        "b = nn.Parameter(torch.randn(BATCH_SIZE, 70).type(torch.FloatTensor))\n",
        "print(a.T.shape, b.shape)\n",
        "c = torch.einsum('ij, jk -> ik', a.T, b)\n",
        "c.shape, c[:,0].shape, c[0, :].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([300, 20]) torch.Size([20, 70])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([300, 70]), torch.Size([300]), torch.Size([70]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AT1eILIstpL2",
        "colab_type": "text"
      },
      "source": [
        "## Modelo - MLPEmb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlFz-R3BiAvN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLPEmb(nn.Module):\n",
        "  def __init__(self, emb_dim, neur1, neur2, drop, out):\n",
        "    super(MLPEmb, self).__init__()\n",
        "    \n",
        "    self.drop = nn.Dropout(drop)\n",
        "    self.relu = nn.ReLU() \n",
        "    \n",
        "    \"\"\" O x já é um glove embedding, então eu vou congelar essa camada \n",
        "        e colocar bias=False para nao desconfigurar o processamento\"\"\"\n",
        "    self.emb = nn.Linear(emb_dim, neur1, bias=False) \n",
        "    \n",
        "    self.fc1 = nn.Linear(neur1, neur2)\n",
        "    self.fc2 = nn.Linear(neur2, out) \n",
        "\n",
        "  def forward(self, x):\n",
        "    o = self.relu(self.emb(x))\n",
        "    o = self.drop(self.relu(self.fc1(o)))\n",
        "    return self.fc2(o)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ai_fkoKBewAC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8ca171f-8261-4a4b-d4f0-148bb9b5fe96"
      },
      "source": [
        "# Hyperparams do modelo MLPEmb\n",
        "EMB_DIM = df_train_emb.shape[1] - 1 # -1  -> col. label\n",
        "H1,H2,D,O, = 75, 22, 0.43, df.label.nunique()\n",
        "\n",
        "model = MLPEmb(EMB_DIM, H1, H2, D, O)\n",
        "x,y = next(iter(train_loader_emb))\n",
        "model(x).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNSHgwIyodSB",
        "colab_type": "text"
      },
      "source": [
        "## Optuna "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rXh0VIY1g4z-",
        "colab": {}
      },
      "source": [
        "EPOCH = 30\n",
        "\n",
        "# Fç trial que busca o melhor optmin e a melhor lr\n",
        "def get_optimizer(trial, model):\n",
        "    optimizer_name = trial.suggest_categorical('optimizer', ['AdaMod', 'Yogi'])\n",
        "    lr_optmzd = trial.suggest_uniform('optim_lr', 3*1e-4, 2*1e-3)\n",
        "    return getattr(optim, optimizer_name)(model.parameters(), lr=lr_optmzd)\n",
        "\n",
        "# Fç obj que max a acc\n",
        "def objective(trial):\n",
        "  h1     = int(trial.suggest_uniform(\"h1_units\", 60, 200))\n",
        "  h2     = int(trial.suggest_uniform(\"h2_units\", 20, 250))\n",
        "  drop   = trial.suggest_uniform(\"drop\", 0.2, 0.7)\n",
        "  smooth = trial.suggest_uniform(\"smooth\", 0.1, 0.35)\n",
        "  \n",
        "  criterion = LabelSmoothing(smooth)     \n",
        "  model     = model = MLPEmb(EMB_DIM, h1, h2, drop, O).to(device)\n",
        "  optimizer = get_optimizer(trial, model)\n",
        "\n",
        "  for step in range(EPOCH):\n",
        "    model.emb.weight.requires_grad = unfrozen = False\n",
        "    loss_train, _ = train(model, device, train_loader_emb, criterion, optimizer)\n",
        "    loss_valid, _, acc = test(model, device, valid_loader_emb, criterion)\n",
        "\n",
        "  return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9GXuvDd-g40R",
        "colab": {}
      },
      "source": [
        "deterministic() # <- ter certeza que tudo foi zerado para o teste ser reproduzível\n",
        "\n",
        "# Running optuna\n",
        "study = optuna.create_study(direction='maximize', sampler=RandomSampler(manualSeed))\n",
        "study.optimize(objective, n_trials=50)\n",
        "print('Number of finished trials: ', len(study.trials))\n",
        "print('Best trial:')\n",
        "trial = study.best_trial\n",
        "print('  Value: ', trial.value)\n",
        "print('  Params: ')\n",
        "\n",
        "for key, value in trial.params.items():\n",
        "    print(f'    {key}: {value}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U0gdn9fGg40b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "b098802c-c5bc-4b61-f671-c5587848153e"
      },
      "source": [
        "# Melhor conj. de params encontrado\n",
        "study.best_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'drop': 0.6325512806526925,\n",
              " 'h1_units': 90.355099267856,\n",
              " 'h2_units': 149.99343931912134,\n",
              " 'optim_lr': 0.0004596988682893509,\n",
              " 'optimizer': 'AdaMod',\n",
              " 'smooth': 0.2272422401667536}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsQZIo1Xk9Zd",
        "colab_type": "text"
      },
      "source": [
        "# Testando a melhor config do modelo com Embeddings pré-Treinados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzsa45WOhRau",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "500a696b-5ba2-44be-e275-205a5b6df9e0"
      },
      "source": [
        "deterministic() \n",
        "\n",
        "# Configura o melhor setup encontrado pelo Optuna\n",
        "H1     = int(study.best_params['h1_units'])\n",
        "H2     = int(study.best_params['h2_units'])\n",
        "D      = study.best_params['drop']\n",
        "SMOOTH = study.best_params['smooth']\n",
        "LR     = study.best_params['optim_lr']\n",
        "\n",
        "model = MLPEmb(EMB_DIM, 91, H2, D, O).to(device)    \n",
        "criterion = LabelSmoothing(SMOOTH)\n",
        "\n",
        "if study.best_params['optimizer'] == 'Lamb':\n",
        "  print(f'Using {study.best_params[\"optimizer\"]}')\n",
        "  optimizer = optim.Lamb(model.parameters(),lr= LR)  \n",
        "else:\n",
        "  print(f'Using {study.best_params[\"optimizer\"]}')\n",
        "  optimizer = optim.AdaMod(model.parameters(),lr= LR)  \n",
        "\n",
        "print(model)\n",
        "# congelando os embeddings para contar os parâmetros treinaveis\n",
        "model.emb.weight.requires_grad = unfrozen = False\n",
        "\n",
        "# Count params\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'\\n############################################\\\n",
        "       \\n# The model has {count_parameters(model):,} trainable parameters #\\\n",
        "       \\n############################################')  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deterministic experiment, seed: 0\n",
            "Using Yogi\n",
            "MLPEmb(\n",
            "  (drop): Dropout(p=0.358600871034648, inplace=False)\n",
            "  (relu): ReLU()\n",
            "  (emb): Linear(in_features=300, out_features=91, bias=False)\n",
            "  (fc1): Linear(in_features=91, out_features=40, bias=True)\n",
            "  (fc2): Linear(in_features=40, out_features=2, bias=True)\n",
            ")\n",
            "\n",
            "############################################       \n",
            "# The model has 3,762 trainable parameters #       \n",
            "############################################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avSg7_KLlScu",
        "colab_type": "text"
      },
      "source": [
        "# Looping de treino com Embeddings congelados\n",
        "\n",
        "---\n",
        "\n",
        "- Para congelar os pesos do embedding basta usar `model.embedding.weight.requires_grad = False`, isso fará com que nenhum gradiente seja calculado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKcpivJTEvlc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvWIZFinExr8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "700dc0b5-8932-44de-fff6-55f046646f8c"
      },
      "source": [
        "torch.tensor([1]).long()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxzx5O6qgljc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "bba9a90c-4883-4816-bd00-b9c2e8421984"
      },
      "source": [
        "%%time\n",
        "import os\n",
        "deterministic() \n",
        "N_EPOCHS   = 100\n",
        "epoch, best_acc = 0,0\n",
        "\n",
        "for step in range(1, N_EPOCHS+1):\n",
        "\n",
        "  # Embeddings Congelados\n",
        "  model.emb.weight.requires_grad = unfrozen = False\n",
        "\n",
        "  loss_train, ppl_train = train(model, device, train_loader_emb, criterion, optimizer)\n",
        "  loss_valid, ppl_valid, acc = test(model, device, valid_loader_emb, criterion)\n",
        "  if acc >= best_acc:\n",
        "    best_acc = acc\n",
        "    epoch    = step\n",
        "    print(f'[Frozen? {not unfrozen}] -- Epoch [{step}/{N_EPOCHS}] |', end=' ')\n",
        "    print(f'Train Loss: {loss_train:.3f} -- Valid Loss: {loss_valid:.3f} --',end=' ')\n",
        "    print(f'Acc: {acc:.3f}')\n",
        "    print(f'Ppl train: {ppl_train:.3f} -- Ppl valid: {ppl_valid:.3f}\\n') \n",
        "\n",
        "print(f'\\nEnd of training. Best Acc: -->[{best_acc:.4f}]<--, at epoch: {epoch}\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deterministic experiment, seed: 0\n",
            "[Frozen? True] -- Epoch [1/100] | Train Loss: 1.691 -- Valid Loss: 0.795 -- Acc: 0.490\n",
            "Ppl train: 5.427 -- Ppl valid: 2.214\n",
            "\n",
            "[Frozen? True] -- Epoch [2/100] | Train Loss: 1.259 -- Valid Loss: 0.722 -- Acc: 0.570\n",
            "Ppl train: 3.522 -- Ppl valid: 2.059\n",
            "\n",
            "[Frozen? True] -- Epoch [3/100] | Train Loss: 1.003 -- Valid Loss: 0.651 -- Acc: 0.680\n",
            "Ppl train: 2.727 -- Ppl valid: 1.917\n",
            "\n",
            "[Frozen? True] -- Epoch [4/100] | Train Loss: 0.870 -- Valid Loss: 0.627 -- Acc: 0.750\n",
            "Ppl train: 2.387 -- Ppl valid: 1.873\n",
            "\n",
            "[Frozen? True] -- Epoch [6/100] | Train Loss: 0.677 -- Valid Loss: 0.589 -- Acc: 0.815\n",
            "Ppl train: 1.968 -- Ppl valid: 1.802\n",
            "\n",
            "[Frozen? True] -- Epoch [8/100] | Train Loss: 0.625 -- Valid Loss: 0.580 -- Acc: 0.815\n",
            "Ppl train: 1.869 -- Ppl valid: 1.787\n",
            "\n",
            "[Frozen? True] -- Epoch [9/100] | Train Loss: 0.612 -- Valid Loss: 0.570 -- Acc: 0.845\n",
            "Ppl train: 1.844 -- Ppl valid: 1.768\n",
            "\n",
            "[Frozen? True] -- Epoch [16/100] | Train Loss: 0.544 -- Valid Loss: 0.556 -- Acc: 0.845\n",
            "Ppl train: 1.723 -- Ppl valid: 1.744\n",
            "\n",
            "[Frozen? True] -- Epoch [23/100] | Train Loss: 0.509 -- Valid Loss: 0.547 -- Acc: 0.850\n",
            "Ppl train: 1.664 -- Ppl valid: 1.727\n",
            "\n",
            "\n",
            "End of training. Best Acc: -->[0.8500]<--, at epoch: 23\n",
            "\n",
            "CPU times: user 8.71 s, sys: 209 ms, total: 8.92 s\n",
            "Wall time: 9.05 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OS4P6Pg6g-DX",
        "colab_type": "text"
      },
      "source": [
        "## end of notebook\n",
        "- EmbeddingBag não ficou bom: culpa do meu processamento que fiz o emb. glove por fora e é um float e o EmbeddingBag precisa de long. \n"
      ]
    }
  ]
}